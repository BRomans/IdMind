{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "svm_classifier.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPcqBBi9U0ReIxKEqxJetLZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BRomans/IdMind/blob/main/svm_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtPuxuOq-NNf"
      },
      "source": [
        "# Run this cell to load required libraries and mount your Drive folder\r\n",
        "import numpy as np\r\n",
        "from numpy.random import choice\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "from google.colab import drive\r\n",
        "import os\r\n",
        "from sklearn.svm import SVC\r\n",
        "from sklearn.base import clone\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "import pandas as pd\r\n",
        "import itertools\r\n",
        "import random\r\n",
        "from time import time"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4SYznPA-O1k"
      },
      "source": [
        "# Seed value\r\n",
        "seed_value = 10\r\n",
        "\r\n",
        "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\r\n",
        "os.environ['PYTHONHASHSEED']=str(seed_value)\r\n",
        "\r\n",
        "# 2. Set `python` built-in pseudo-random generator at a fixed value\r\n",
        "random.seed(seed_value)\r\n",
        "\r\n",
        "# 3. Set `numpy` pseudo-random generator at a fixed value\r\n",
        "np.random.seed(seed_value)"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNZSc0rp-PK2",
        "outputId": "ce9d7f63-6509-42dc-a488-f435636a6d39"
      },
      "source": [
        "drive.mount('/content/drive')\r\n",
        "dirpath = \"/content/drive/MyDrive/ml2-eeg-biometrics/train-test-data/\" "
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oM4oGTnlLBhh"
      },
      "source": [
        "class SVM_one_v_all:\r\n",
        "  def __init__(self, C=1.0, kernel='rbf', degree=3, gamma='scale', random_state=None, verification=False):\r\n",
        "    self.C = C\r\n",
        "    self.kernel = kernel\r\n",
        "    self.degree = degree\r\n",
        "    self.gamma = gamma\r\n",
        "    self.random_state = random_state\r\n",
        "    self.svm = SVC(C=C, kernel=kernel, degree=degree, gamma=gamma, random_state=random_state, probability=True)\r\n",
        "    self.verification=verification\r\n",
        "\r\n",
        "  def fit(self, x_train, y_train, size_factor = 3, verbose=True):\r\n",
        "    self.y_train = y_train\r\n",
        "    self.x_train = x_train\r\n",
        "    class_values = np.unique(y_train)\r\n",
        "    self.class_values = class_values\r\n",
        "    svm_list = []\r\n",
        "\r\n",
        "    for c in class_values:\r\n",
        "      if verbose: print(c)\r\n",
        "      c_inds = np.where(y_train == c)[0]\r\n",
        "\r\n",
        "      non_c_inds = np.where(y_train != c)[0]\r\n",
        "      size_factor = size_factor if size_factor < len(non_c_inds)/len(c_inds) else len(non_c_inds)/len(c_inds)\r\n",
        "\r\n",
        "      non_c_inds = choice(non_c_inds, size=int(len(c_inds)*size_factor), replace=False)                 # Take random subset of examples of other classes. size = the number of positive class examples times a user-specified size_factor.\r\n",
        "      \r\n",
        "      x_subset = np.zeros((len(c_inds)+len(non_c_inds), x_train.shape[1]))\r\n",
        "      y_subset = np.zeros(len(c_inds)+len(non_c_inds))\r\n",
        "\r\n",
        "      x_subset[:len(c_inds),:] = x_train[c_inds,:]\r\n",
        "      x_subset[len(c_inds):,:] = x_train[non_c_inds,:]\r\n",
        "\r\n",
        "      y_subset[:len(c_inds)] = 1\r\n",
        "\r\n",
        "      clf = clone(self.svm)\r\n",
        "      clf.fit(x_subset, y_subset)\r\n",
        "\r\n",
        "      svm_list.append(clf)\r\n",
        "    \r\n",
        "    self.svm_list = svm_list\r\n",
        "\r\n",
        "  def predict(self, x_test, verbose=True, class_ver=None):\r\n",
        "\r\n",
        "    class_values = self.class_values\r\n",
        "\r\n",
        "    if not self.verification:\r\n",
        "      preds = np.zeros(len(x_test))\r\n",
        "      max_probs = np.zeros(len(x_test))\r\n",
        "\r\n",
        "      for i, model in enumerate(self.svm_list):\r\n",
        "        if verbose: print(class_values[i])\r\n",
        "        probs = model.predict_proba(x_test)[:,1]\r\n",
        "        \r\n",
        "        preds[probs > max_probs] = class_values[i]\r\n",
        "        max_probs[probs > max_probs] = probs[probs > max_probs]\r\n",
        "\r\n",
        "    elif class_ver is not None:\r\n",
        "      class_ind = np.where(class_values == class_ver)[0][0]\r\n",
        "      print(class_ind)\r\n",
        "\r\n",
        "      preds = self.svm_list[class_ind].predict(x_test)\r\n",
        "    \r\n",
        "    else:\r\n",
        "      raise ValueError(\"verification is set to True, please supply class_ver.\")\r\n",
        "    \r\n",
        "    return preds\r\n",
        "\r\n",
        "  def grid_search(self, x_train, y_train, x_valid, y_valid, params, data_name=''):\r\n",
        "    \r\n",
        "    if  len(params['kernel'])==0 | len(params['C'])==0 | len(params['gamma'])==0 | len(params['degree'])==0:\r\n",
        "      raise ValueError(\"At least one value must be supplied for kernel, C, gamma, and degree.\")\r\n",
        "\r\n",
        "    count=0\r\n",
        "    filepath = '/content/drive/MyDrive/ml2-eeg-biometrics/classification-results.csv'\r\n",
        "\r\n",
        "    for kernel in params['kernel']:\r\n",
        "      for C in params['C']:\r\n",
        "        for gamma in params['gamma']:\r\n",
        "          for degree in params['degree']:\r\n",
        "            print(\"-\"*40)\r\n",
        "            print(\"{}: kernel: {}, C: {}, gamma: {}, degree: {}\".format(count, kernel, C, gamma, degree))\r\n",
        "            self.svm = SVC(C=C, kernel=kernel, degree=degree, gamma=gamma, random_state=self.random_state, probability=True)\r\n",
        "\r\n",
        "            print(' Fitting....')\r\n",
        "            self.fit(x_train, y_train, verbose=False)\r\n",
        "\r\n",
        "            print(' Calculating results....')\r\n",
        "            train_pred = self.predict(x_train, verbose=False)\r\n",
        "            train_acc = accuracy_score(y_train, train_pred)\r\n",
        "            print(\"train_acc: {0:.3f}\".format(train_acc))\r\n",
        "\r\n",
        "            valid_pred = self.predict(x_valid, verbose=False)\r\n",
        "            valid_acc = accuracy_score(y_valid, valid_pred)\r\n",
        "            print(\"validation_acc: {0:.3f}\".format(valid_acc))\r\n",
        "\r\n",
        "            mode = 'a' if os.path.isfile(filepath) else 'w'\r\n",
        "\r\n",
        "            timestamp = pd.Timestamp.now()\r\n",
        "            line = ','.join(map(str, [data_name,count,timestamp,kernel,C,gamma,degree,train_acc,valid_acc]))\r\n",
        "            print(line)\r\n",
        "            with open(filepath, mode) as file:\r\n",
        "              file.write(line + '\\n')\r\n",
        "\r\n",
        "            count+=1\r\n",
        "\r\n",
        "  def add_test_class(self, x_test, y_test, id_test):\r\n",
        "\r\n",
        "    if len(np.unique(y_test)) != 1:\r\n",
        "      raise ValueError(\"More than one class found in y_test.\")\r\n",
        "\r\n",
        "    class_values = self.class_values\r\n",
        "    svm_list = self.svm_list\r\n",
        "\r\n",
        "    new_class = np.unique(y_test)[0]\r\n",
        "    class_values = np.append(class_values, new_class)                             # Add the new class to the array of classes.\r\n",
        "\r\n",
        "    clf = clone(self.svm)\r\n",
        "    svm_list.append(clf)\r\n",
        "\r\n",
        "    self.svm_list = svm_list\r\n",
        "    self.class_values = class_values\r\n",
        "\r\n",
        "    train_scores, test_scores = [], []\r\n",
        "\r\n",
        "    for run in ['Run1','Run2','Run3','Run4','Run5','Run6']:\r\n",
        "      print(run, \"...\")\r\n",
        "      x_test_test = x_test[id_test[:,2] == run,:]                             # Get the rows of data for the relevant run - this will be our test set.\r\n",
        "      x_test_train = x_test[id_test[:,2] != run,:]                            # Get the rows of data for the other 5 runs - this will be our training set.\r\n",
        "\r\n",
        "      inds = choice(range(len(self.x_train)), size = len(x_test_train)*3, replace=False)\r\n",
        "\r\n",
        "      x_train_subset = np.concatenate((self.x_train[inds,:], x_test_train))\r\n",
        "      y_train_subset = np.concatenate((np.zeros(len(inds)), np.ones(len(x_test_train))))\r\n",
        "\r\n",
        "      clf.fit(x_train_subset, y_train_subset)  \r\n",
        "\r\n",
        "      y_pred_train = self.predict(x_test_train, verbose=False)\r\n",
        "      y_pred_test = self.predict(x_test_test, verbose=False)\r\n",
        "\r\n",
        "      train_scores.append(accuracy_score(np.array([new_class]*len(y_pred_train)), y_pred_train))\r\n",
        "      test_scores.append(accuracy_score(np.array([new_class]*len(y_pred_test)), y_pred_test))\r\n",
        "\r\n",
        "    print(\"train accuracy: {}, test accuracy: {}\".format(np.mean(train_scores), np.mean(test_scores)))\r\n",
        "\r\n",
        "    return train_scores, test_scores"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jka-YQd15pvm"
      },
      "source": [
        "#### Classification Performance Report\r\n",
        "Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T2-AsYR_KFv"
      },
      "source": [
        "# Structure to evaluate classification performance\r\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\r\n",
        "\r\n",
        "def print_results(Y_test, predictions, label_names):\r\n",
        "    print(classification_report(Y_test, predictions))\r\n",
        "    print(\"Classification Accuracy: {0:.3f}\".format(accuracy_score(Y_test, predictions)))\r\n",
        "\r\n",
        "    conf_mat = confusion_matrix(Y_test, predictions)\r\n",
        "\r\n",
        "    fig = plt.figure(figsize=(6,6))\r\n",
        "    width = np.shape(conf_mat)[1]\r\n",
        "    height = np.shape(conf_mat)[0]\r\n",
        "\r\n",
        "    plt.figure(figsize=(12,12))\r\n",
        "    res = plt.imshow(np.array(conf_mat), cmap=plt.cm.summer, interpolation='nearest')\r\n",
        "    for i, row in enumerate(conf_mat):\r\n",
        "        for j, c in enumerate(row):\r\n",
        "            if c>0:\r\n",
        "                plt.text(j-.2, i+.1, c, fontsize=16)\r\n",
        "\r\n",
        "    # cb = fig.colorbar(res)\r\n",
        "    plt.title('Confusion Matrix')\r\n",
        "    # _ = plt.xticks(range(6), label_names, rotation=90)\r\n",
        "    # _ = plt.yticks(range(6), label_names)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0JX2t-U5Fkf"
      },
      "source": [
        "#### Initial set of encodings for testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBcFWrOF-Qho"
      },
      "source": [
        "# # Load one set of data.\r\n",
        "# x_train = np.load(dirpath + 'train_encoding_model_2021-01-19 19:36:47.206950.npy')\r\n",
        "# x_valid = np.load(dirpath + 'valid_encoding_model_2021-01-19 19:36:47.206950.npy')\r\n",
        "\r\n",
        "# y_train = np.load(dirpath + 'y_train.npy')\r\n",
        "# y_train = y_train.reshape((-1,))\r\n",
        "\r\n",
        "# y_valid= np.load(dirpath + 'y_valid.npy', allow_pickle=True)\r\n",
        "# y_valid = y_valid.reshape((-1,))\r\n",
        "# y_valid = np.array(y_valid, dtype='int64') # Read in as object vector with allow_pickle, not sure why.\r\n",
        "\r\n",
        "# id_train = np.load(dirpath + 'id_train.npy', allow_pickle=True)\r\n",
        "# id_train = id_train.reshape((-1, 5))\r\n",
        "\r\n",
        "# id_valid = np.load(dirpath + 'id_valid.npy', allow_pickle=True)\r\n",
        "# id_valid = id_valid.reshape((-1, 5))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCiTsyDciqH2"
      },
      "source": [
        "dirpath = \"/content/drive/MyDrive/ml2-eeg-biometrics/saved_encoders/encodings/\"\r\n",
        "file_list = os.listdir(dirpath)\r\n",
        "\r\n",
        "params = {'kernel':['rbf'], 'C':[10.0], 'gamma':['scale'], 'degree':[3]}\r\n",
        "\r\n",
        "\r\n",
        "for model_num in [19,27,17]:\r\n",
        "  prev=time()\r\n",
        "  train_file = [f for f in file_list if f.startswith(str(model_num) + '_train')][0]\r\n",
        "  validation_file = [f for f in file_list if f.startswith(str(model_num) + '_valid')][0]\r\n",
        "  print(\"=\"*80)\r\n",
        "  print(\"Model {}:\\n Loading data....\".format(model_num))\r\n",
        "  x_train = np.load(dirpath + train_file)\r\n",
        "  x_valid = np.load(dirpath + validation_file)\r\n",
        "\r\n",
        "  svm = SVM_one_v_all(random_state=0)\r\n",
        "\r\n",
        "  svm.grid_search(x_train, y_train, x_valid, y_valid, params=params, data_name=str(model_num))\r\n",
        "\r\n",
        "  print(round(time()-prev, 5), \" seconds\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5-uSBjVyVO1",
        "outputId": "d454cd9d-b665-4eb8-8e24-0e2c2ddd8173"
      },
      "source": [
        "dirpath = \"/content/drive/MyDrive/ml2-eeg-biometrics/saved_encoders/encodings/\"\r\n",
        "file_list = os.listdir(dirpath)\r\n",
        "\r\n",
        "params = {'kernel':['rbf'], 'C':[10.0], 'gamma':[6.0e-3], 'degree':[2]}\r\n",
        "# params = {'kernel':['rbf'], 'C':[10.0], 'gamma':['scale'], 'degree':[2]}\r\n",
        "\r\n",
        "chosen_model = 17\r\n",
        "\r\n",
        "prev=time()\r\n",
        "train_file = [f for f in file_list if f.startswith(str(chosen_model) + '_train'])[0]\r\n",
        "validation_file = [f for f in file_list if f.startswith(str(chosen_model) + '_valid')][0]\r\n",
        "print(\"=\"*80)\r\n",
        "print(\"Model {}:\\n Loading data....\".format(chosen_model))\r\n",
        "x_train = np.load(dirpath + train_file)\r\n",
        "x_valid = np.load(dirpath + validation_file)\r\n",
        "\r\n",
        "svm = SVM_one_v_all(random_state=0)\r\n",
        "\r\n",
        "svm.grid_search(x_train, y_train, x_valid, y_valid, params=params, data_name=str(chosen_model))\r\n",
        "\r\n",
        "print(round(time()-prev, 5), \" seconds\")"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "Model 17:\n",
            " Loading data....\n",
            "0.02276  seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHNZmwQBAIvc"
      },
      "source": [
        "y_pred = svm.predict(x_valid)\r\n",
        "\r\n",
        "print_results(y_valid, y_pred, np.unique(y_valid))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luesV02Pzo77"
      },
      "source": [
        "### Test unseen class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQ33rxL06GGz"
      },
      "source": [
        "##### Load test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yH7gyLR7qUy6",
        "outputId": "6776767c-ee43-48f2-86fd-6437d2b201be"
      },
      "source": [
        "x_test = np.load(\"/content/drive/MyDrive/ml2-eeg-biometrics/saved_encoders/test_encodings/17_test_encoding.npy\")\r\n",
        "\r\n",
        "y_test = np.load(\"/content/drive/MyDrive/ml2-eeg-biometrics/train-test-data/y_test.npy\", allow_pickle=True)\r\n",
        "y_test = y_test.reshape((-1))\r\n",
        "y_test = np.array(y_test, dtype='int64') # Read in as object vector with allow_pickle, not sure why.\r\n",
        "\r\n",
        "id_test = np.load(\"/content/drive/MyDrive/ml2-eeg-biometrics/train-test-data/id_test.npy\", allow_pickle=True)\r\n",
        "id_test = id_test.reshape((-1,5))\r\n",
        "\r\n",
        "print(\"Shapes: \", x_test.shape, y_test.shape, id_test.shape)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(419, 250) (419,) (419, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdOZNaq16J1c"
      },
      "source": [
        "##### Fit the model on the training data initially."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYKuBx5nrJhC"
      },
      "source": [
        "svm_final = SVM_one_v_all(random_state=0, C=10.0, kernel='rbf', degree=2, gamma=0.006)\r\n",
        "\r\n",
        "svm_final.fit(x_train, y_train, verbose=False)"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqF_Jo-qr-CG",
        "outputId": "957b540f-964c-4f95-aaea-a595153dc477"
      },
      "source": [
        "svm_final.add_test_class(x_test, y_test, id_test)"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Run1 ...\n",
            "Run2 ...\n",
            "Run3 ...\n",
            "Run4 ...\n",
            "Run5 ...\n",
            "Run6 ...\n",
            "train accuracy: 1.0, test accuracy: 0.8808143547273982\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
              " [0.8571428571428571,\n",
              "  0.9420289855072463,\n",
              "  0.9285714285714286,\n",
              "  0.8857142857142857,\n",
              "  0.7857142857142857,\n",
              "  0.8857142857142857])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GVdV_6e9gmp"
      },
      "source": [
        "x_train_18 = x_train[y_train != 18,:]\r\n",
        "y_train_18 = y_train[y_train != 18]\r\n",
        "\r\n",
        "svm_final_debug = SVM_one_v_all(random_state=0, C=10.0, kernel='rbf', degree=2, gamma=0.006)\r\n",
        "\r\n",
        "svm_final_debug.fit(x_train_18, y_train_18, verbose=False)"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtKf9xB6CvJ9",
        "outputId": "bed3b6a9-43ba-4694-a4e3-32e40e542fe0"
      },
      "source": [
        "svm_final_debug.add_test_class(x_train[y_train==18,:], y_train[y_train==3], id_train[y_train==18,:])"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18 18\n",
            "Run1 ...\n",
            "1.0\n",
            "0.9714285714285714\n",
            "Run2 ...\n",
            "1.0\n",
            "0.9714285714285714\n",
            "Run3 ...\n",
            "1.0\n",
            "0.9142857142857143\n",
            "Run4 ...\n",
            "1.0\n",
            "0.9714285714285714\n",
            "Run6 ...\n",
            "1.0\n",
            "0.9857142857142858\n",
            "train accuracy: 0.8442857142857143, test accuracy: 0.29714285714285715\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0.8428571428571429,\n",
              "  0.9142857142857143,\n",
              "  0.8107142857142857,\n",
              "  0.825,\n",
              "  0.8285714285714286],\n",
              " [0.22857142857142856,\n",
              "  0.4142857142857143,\n",
              "  0.2571428571428571,\n",
              "  0.3,\n",
              "  0.2857142857142857])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mfwj5NvC4wC4"
      },
      "source": [
        "### Performance on subset of classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "XC6jbbgEzBQs",
        "outputId": "adea543c-93f2-4586-ea44-e4c633eded2c"
      },
      "source": [
        "### Test performance when number of partipicants/identities to predict is lower.\r\n",
        "n_classes = 1\r\n",
        "x_train_subset = x_train[y_train < n_classes]\r\n",
        "y_train_subset = y_train[y_train < n_classes]\r\n",
        "x_valid_subset = x_valid[y_valid < n_classes]\r\n",
        "y_valid_subset = y_valid[y_valid < n_classes]\r\n",
        "\r\n",
        "params = {'kernel':['rbf'], 'C':[10.0], 'gamma':['scale'], 'degree':[2]}\r\n",
        "# params = {'kernel':['rbf'], 'C':[10.0], 'gamma':['scale'], 'degree':[2]}\r\n",
        "\r\n",
        "chosen_model = 17\r\n",
        "\r\n",
        "prev=time()\r\n",
        "\r\n",
        "svm = SVM_one_v_all(random_state=0, verification=True)\r\n",
        "\r\n",
        "# svm.grid_search(x_train_subset, y_train_subset, x_valid_subset, y_valid_subset, params=params, data_name=str(chosen_model)+'-(2 classes)')\r\n",
        "\r\n",
        "svm.fit(x_train, y_train)\r\n",
        "svm.predict(x_train_subset, class_ver==0)\r\n",
        "\r\n",
        "print(round(time()-prev, 5), \" seconds\")"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-103-bf8e87f03510>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# svm.grid_search(x_train_subset, y_train_subset, x_valid_subset, y_valid_subset, params=params, data_name=str(chosen_model)+'-(2 classes)')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_subset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_ver\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-102-23d7c90af8bc>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x_train, y_train, size_factor, verbose)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m       \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m       \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_subset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m       \u001b[0msvm_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uI-SS_fBnOOQ"
      },
      "source": [
        "### Test verification approach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yz1RHsPk8NL"
      },
      "source": [
        "# ### Test performance when number of partipicants/identities to predict is lower.\r\n",
        "# n_classes = 1\r\n",
        "# x_train_subset = x_train[y_train < n_classes]\r\n",
        "# y_train_subset = y_train[y_train < n_classes]\r\n",
        "# x_valid_subset = x_valid[y_valid < n_classes]\r\n",
        "# y_valid_subset = y_valid[y_valid < n_classes]\r\n",
        "\r\n",
        "params = {'kernel':['rbf'], 'C':[10.0], 'gamma':['scale'], 'degree':[2]}\r\n",
        "# params = {'kernel':['rbf'], 'C':[10.0], 'gamma':['scale'], 'degree':[2]}\r\n",
        "\r\n",
        "chosen_model = 17\r\n",
        "\r\n",
        "prev=time()\r\n",
        "\r\n",
        "# svm = SVM_one_v_all(random_state=0, verification=True)\r\n",
        "\r\n",
        "# svm.fit(x_train, y_train)\r\n",
        "train_pred = svm.predict(x_train, class_ver=1)\r\n",
        "valid_pred = svm.predict(x_valid, class_ver=1)\r\n",
        "\r\n",
        "y_train_true = y_train ==1\r\n",
        "y_valid_true = y_valid==1\r\n",
        "\r\n",
        "print_results(y_valid_true, valid_pred, np.unique(y_valid_true))\r\n",
        "\r\n",
        "print(round(time()-prev, 5), \" seconds\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OED30XoFCQz4"
      },
      "source": [
        "id_train_df = pd.DataFrame(id_train, columns=['Subject', 'Date','Run','Task','Trial'])\r\n",
        "\r\n",
        "# Get the minimum date for each subject.\r\n",
        "df = id_train_df.groupby(by='Subject', as_index=False).max('Date')[['Subject','Date']]\r\n",
        "min_dates = df.astype(str).agg('-'.join, axis=1).values                                 # Convert (Date) to string and concatenate the Subject and Date\r\n",
        "\r\n",
        "rel_ind = np.in1d(id_train[:,0] + '-' + id_train[:,1].astype(str), min_dates)\r\n",
        "\r\n",
        "x_train_1session = x_train[rel_ind]\r\n",
        "y_train_1session = y_train[rel_ind]\r\n",
        "\r\n",
        "rel_ind = np.in1d(id_valid[:,0] + '-' + id_valid[:,1].astype(str), min_dates)\r\n",
        "\r\n",
        "x_valid_1session = x_valid[rel_ind]\r\n",
        "y_valid_1session = y_valid[rel_ind]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}