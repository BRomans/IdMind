{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "svm_classifier.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNR1gMy+X3z7XswFEbH8MHv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BRomans/IdMind/blob/main/svm_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtPuxuOq-NNf"
      },
      "source": [
        "# Run this cell to load required libraries and mount your Drive folder\r\n",
        "import numpy as np\r\n",
        "from numpy.random import choice\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "from google.colab import drive\r\n",
        "import os\r\n",
        "from sklearn.svm import SVC\r\n",
        "from sklearn.base import clone\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "import pandas as pd\r\n",
        "import itertools\r\n",
        "import random\r\n",
        "from time import time"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4SYznPA-O1k"
      },
      "source": [
        "# Seed value\r\n",
        "seed_value = 10\r\n",
        "\r\n",
        "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\r\n",
        "os.environ['PYTHONHASHSEED']=str(seed_value)\r\n",
        "\r\n",
        "# 2. Set `python` built-in pseudo-random generator at a fixed value\r\n",
        "random.seed(seed_value)\r\n",
        "\r\n",
        "# 3. Set `numpy` pseudo-random generator at a fixed value\r\n",
        "np.random.seed(seed_value)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNZSc0rp-PK2",
        "outputId": "056932fa-5247-489e-f53b-a52aed3a7865"
      },
      "source": [
        "drive.mount('/content/drive')\r\n",
        "dirpath = \"/content/drive/MyDrive/ml2-eeg-biometrics/train-test-data/\" "
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oM4oGTnlLBhh"
      },
      "source": [
        "class SVM_one_v_all:\r\n",
        "  def __init__(self, C=1.0, kernel='rbf', degree=3, random_state=None):\r\n",
        "    self.C = C\r\n",
        "    self.kernel = kernel\r\n",
        "    self.degree = degree\r\n",
        "    self.random_state = random_state\r\n",
        "    self.svm = SVC(C=C, kernel=kernel, degree=degree, random_state=random_state, probability=True)\r\n",
        "\r\n",
        "  def fit(self, x_train, y_train, size_factor = 3, verbose=True):\r\n",
        "    self.y_train = y_train\r\n",
        "    class_values = np.unique(y_train)\r\n",
        "    self.class_values = class_values\r\n",
        "    svm_list = []\r\n",
        "\r\n",
        "    for c in class_values:\r\n",
        "      if verbose: print(c)\r\n",
        "      c_inds = np.where(y_train == c)[0]\r\n",
        "\r\n",
        "      non_c_inds = np.where(y_train != c)[0]\r\n",
        "      size_factor = size_factor if size_factor < len(non_c_inds)/len(c_inds) else len(non_c_inds)/len(c_inds)\r\n",
        "\r\n",
        "      non_c_inds = choice(non_c_inds, size=int(len(c_inds)*size_factor), replace=False)                 # Take random subset of examples of other classes. size = the number of positive class examples times a user-specified size_factor.\r\n",
        "      \r\n",
        "      x_subset = np.zeros((len(c_inds)+len(non_c_inds), x_train.shape[1]))\r\n",
        "      y_subset = np.zeros(len(c_inds)+len(non_c_inds))\r\n",
        "\r\n",
        "      x_subset[:len(c_inds),:] = x_train[c_inds,:]\r\n",
        "      x_subset[len(c_inds):,:] = x_train[non_c_inds,:]\r\n",
        "\r\n",
        "      y_subset[:len(c_inds)] = 1\r\n",
        "\r\n",
        "      clf = clone(self.svm)\r\n",
        "      clf.fit(x_subset, y_subset)\r\n",
        "\r\n",
        "      svm_list.append(clf)\r\n",
        "    \r\n",
        "    self.svm_list = svm_list\r\n",
        "\r\n",
        "  def predict(self, x_test, verbose=True):\r\n",
        "\r\n",
        "    preds = np.zeros(len(x_test))\r\n",
        "    max_probs = np.zeros(len(x_test))\r\n",
        "    class_values = self.class_values\r\n",
        "\r\n",
        "    for i, model in enumerate(self.svm_list):\r\n",
        "      if verbose: print(class_values[i])\r\n",
        "      probs = model.predict_proba(x_test)[:,1]\r\n",
        "      \r\n",
        "      preds[probs > max_probs] = class_values[i]\r\n",
        "      max_probs[probs > max_probs] = probs[probs > max_probs]\r\n",
        "\r\n",
        "      if i == len(self.svm_list)-1:\r\n",
        "        print(sum(max_probs>0.5)/len(max_probs))\r\n",
        "    \r\n",
        "    return preds\r\n",
        "\r\n",
        "  def grid_search(self, x_train, y_train, x_valid, y_valid, params, data_name=''):\r\n",
        "    \r\n",
        "    if  len(params['kernel'])==0 | len(params['C'])==0 | len(params['gamma'])==0 | len(params['degree'])==0:\r\n",
        "      raise ValueError(\"At least one value must be supplied for kernel, C, gamma, and degree.\")\r\n",
        "\r\n",
        "    count=0\r\n",
        "    filepath = '/content/drive/MyDrive/ml2-eeg-biometrics/classification-results.csv'\r\n",
        "\r\n",
        "    for kernel in params['kernel']:\r\n",
        "      for C in params['C']:\r\n",
        "        for gamma in params['gamma']:\r\n",
        "          for degree in params['degree']:\r\n",
        "            print(\"-\"*40)\r\n",
        "            print(\"{}: kernel: {}, C: {}, gamma: {}, degree: {}\".format(count, kernel, C, gamma, degree))\r\n",
        "            self.svm = SVC(C=C, kernel=kernel, degree=degree, gamma=gamma, random_state=self.random_state, probability=True)\r\n",
        "\r\n",
        "            print('Fitting....')\r\n",
        "            self.fit(x_train, y_train, verbose=False)\r\n",
        "\r\n",
        "            print('Calculating results....')\r\n",
        "            train_pred = self.predict(x_train, verbose=False)\r\n",
        "            train_acc = accuracy_score(y_train, train_pred)\r\n",
        "            print(\"train_acc: {0:.3f}\".format(train_acc))\r\n",
        "\r\n",
        "            valid_pred = self.predict(x_valid, verbose=False)\r\n",
        "            valid_acc = accuracy_score(y_valid, valid_pred)\r\n",
        "            print(\"validation_acc: {0:.3f}\".format(valid_acc))\r\n",
        "\r\n",
        "            mode = 'a' if os.path.isfile(filepath) else 'w'\r\n",
        "\r\n",
        "            timestamp = pd.Timestamp.now()\r\n",
        "            line = ','.join(map(str, [data_name,count,timestamp,kernel,C,gamma,degree,train_acc,valid_acc]))\r\n",
        "            print(line)\r\n",
        "            with open(filepath, mode) as file:\r\n",
        "              file.write(line + '\\n')\r\n",
        "\r\n",
        "            count+=1"
      ],
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T2-AsYR_KFv"
      },
      "source": [
        "# Structure to evaluate classification performance\r\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\r\n",
        "\r\n",
        "def print_results(Y_test, predictions, label_names):\r\n",
        "    print(classification_report(Y_test, predictions))\r\n",
        "    print(\"Classification Accuracy: {0:.3f}\".format(accuracy_score(Y_test, predictions)))\r\n",
        "\r\n",
        "    conf_mat = confusion_matrix(Y_test, predictions)\r\n",
        "\r\n",
        "    fig = plt.figure(figsize=(6,6))\r\n",
        "    width = np.shape(conf_mat)[1]\r\n",
        "    height = np.shape(conf_mat)[0]\r\n",
        "\r\n",
        "    plt.figure(figsize=(12,12))\r\n",
        "    res = plt.imshow(np.array(conf_mat), cmap=plt.cm.summer, interpolation='nearest')\r\n",
        "    for i, row in enumerate(conf_mat):\r\n",
        "        for j, c in enumerate(row):\r\n",
        "            if c>0:\r\n",
        "                plt.text(j-.2, i+.1, c, fontsize=16)\r\n",
        "\r\n",
        "    # cb = fig.colorbar(res)\r\n",
        "    plt.title('Confusion Matrix')\r\n",
        "    # _ = plt.xticks(range(6), label_names, rotation=90)\r\n",
        "    # _ = plt.yticks(range(6), label_names)"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBcFWrOF-Qho"
      },
      "source": [
        "# Load one set of data.\r\n",
        "x_train = np.load(dirpath + 'train_encoding_model_2021-01-19 19:36:47.206950.npy')\r\n",
        "x_valid = np.load(dirpath + 'valid_encoding_model_2021-01-19 19:36:47.206950.npy')\r\n",
        "\r\n",
        "y_train = np.load(dirpath + 'y_train.npy')\r\n",
        "y_train = y_train.reshape((-1,))\r\n",
        "\r\n",
        "y_valid= np.load(dirpath + 'y_valid.npy', allow_pickle=True)\r\n",
        "y_valid = y_valid.reshape((-1,))\r\n",
        "y_valid = np.array(y_valid, dtype='int64') # Read in as object vector with allow_pickle, not sure why.\r\n",
        "\r\n",
        "id_train = np.load(dirpath + 'id_train.npy', allow_pickle=True)\r\n",
        "id_train = id_train.reshape((-1, 5))\r\n",
        "\r\n",
        "id_valid = np.load(dirpath + 'id_valid.npy', allow_pickle=True)\r\n",
        "id_valid = id_valid.reshape((-1, 5))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xDBmgD45w_O",
        "outputId": "aead6511-acbb-4862-ec80-5cad66f84d22"
      },
      "source": [
        "params = {'kernel':['rbf'], 'C':[10.0], 'gamma':[0.00277], 'degree':[3]}\r\n",
        "\r\n",
        "svm = SVM_one_v_all(random_state=0)\r\n",
        "\r\n",
        "prev=time()\r\n",
        "\r\n",
        "svm.grid_search(x_train, y_train, x_valid, y_valid, params=params)\r\n",
        "\r\n",
        "print(round(time()-prev, 5), \" seconds\")"
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------\n",
            "0: kernel: rbf, C: 10.0, gamma: 0.00277, degree: 3\n",
            "Fitting....\n",
            "Calculating results....\n",
            "0.8859714928732183\n",
            "train_acc: 0.567\n",
            "0.8338461538461538\n",
            "validation_acc: 0.392\n",
            ",0,2021-01-22 00:01:36.250324,rbf,10.0,0.00277,3,0.5674418604651162,0.3923076923076923\n",
            "83.50564  seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OED30XoFCQz4"
      },
      "source": [
        "id_train_df = pd.DataFrame(id_train, columns=['Subject', 'Date','Run','Task','Trial'])\r\n",
        "\r\n",
        "# Get the minimum date for each subject.\r\n",
        "df = id_train_df.groupby(by='Subject', as_index=False).max('Date')[['Subject','Date']]\r\n",
        "min_dates = df.astype(str).agg('-'.join, axis=1).values                                 # Convert (Date) to string and concatenate the Subject and Date\r\n",
        "\r\n",
        "rel_ind = np.in1d(id_train[:,0] + '-' + id_train[:,1].astype(str), min_dates)\r\n",
        "\r\n",
        "x_train_1session = x_train[rel_ind]\r\n",
        "y_train_1session = y_train[rel_ind]\r\n",
        "\r\n",
        "rel_ind = np.in1d(id_valid[:,0] + '-' + id_valid[:,1].astype(str), min_dates)\r\n",
        "\r\n",
        "x_valid_1session = x_valid[rel_ind]\r\n",
        "y_valid_1session = y_valid[rel_ind]"
      ],
      "execution_count": 76,
      "outputs": []
    }
  ]
}