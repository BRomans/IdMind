{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "eeg_biometrics.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkWW2ddS9Tqb"
      },
      "source": [
        "# EEG Biometrics\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCJoISV69Ugz"
      },
      "source": [
        "# Run this cell to load required libraries and mount your Drive folder\r\n",
        "import numpy as np\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "from google.colab import drive\r\n",
        "import os\r\n",
        "from sklearn.svm import SVC\r\n",
        "import pandas as pd\r\n",
        "import itertools\r\n",
        "\r\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQJYj9_AoPIv"
      },
      "source": [
        "\r\n",
        "class pairwiseSVM:\r\n",
        "  \"\"\"\r\n",
        "  Define the SVM class which will handle the pairwise manipulation, training & prediction\r\n",
        "  \"\"\"\r\n",
        "  def __init__(self, C=1.0, kernel='rbf', degree=3, random_state=None):\r\n",
        "    self.svm = SVC(C=C, kernel=kernel, degree=degree, random_state=random_state)\r\n",
        "\r\n",
        "  def read_train_data(filename, label_col = 'labels', id_col = 'id'):\r\n",
        "    \"\"\"\r\n",
        "    The training data may be read from file or supplied as a DF when fitting the classifier. \r\n",
        "    In both cases, it is assumed that is in DF format with column names, and includes class labels and trial IDs.\r\n",
        "    \"\"\"\r\n",
        "    data = pd.read_csv(filename)\r\n",
        "\r\n",
        "    # Separate the trial IDs, class labels and feature data into separate numpy arrays.\r\n",
        "    train_id = np.array(data[id_col]) # Retrieve the trial IDs for each row & convert to numpy array.\r\n",
        "    y_train = np.array(data[label_col]) # Retrieve the class labels for each row & convert to numpy array.\r\n",
        "    # Retrieve the training features only and convert to numpy array.\r\n",
        "    x_train = data.drop([label_col, id_col], axis=1)\r\n",
        "    x_train = np.array(x_train)\r\n",
        "\r\n",
        "    self.train_id = train_id\r\n",
        "    self.y_train = y_train\r\n",
        "    self.x_train = x_train\r\n",
        "\r\n",
        "  def construct_pairs(self, x_train=None, y_train=None, x_test = None, y_test = None):\r\n",
        "    \"\"\"\r\n",
        "    Method for constructing pairs from the training or testing data.\r\n",
        "    \"\"\"\r\n",
        "    if (x_train is None) ^ (y_train is None):\r\n",
        "      raise Exception(\"Both x_train and y_train datasets should be supplied, or neither.\")\r\n",
        "    elif x_train is None and y_train is None:\r\n",
        "      x_train = self.x_train\r\n",
        "      y_train = self.y_train\r\n",
        "\r\n",
        "\r\n",
        "    # If x_test is not supplied, we want to construct all pairs of the training data with itself.\r\n",
        "    if x_test is None:\r\n",
        "      # Using the permutations function allows us to get symmetric pairs but excludes pairs of the same index. i.e. both (i,j) and (j,i) will be included but only where i!=j\r\n",
        "      index_pairs = itertools.permutations(range(len(x_train)), 2) # Get all two-way permutations of the indexes.\r\n",
        "\r\n",
        "      n_pairs = len(x_train)*len(x_train) - len(x_train) # All two-way combinations except where the indexes are the same.\r\n",
        "      x_pairs = np.zeros((n_pairs, x_train.shape[1]*2)) # Create a blank array to hold the concatenated feature vector pairs.\r\n",
        "      y_pairs = np.zeros(n_pairs) # Create a blank vector to hold class similarity flag.\r\n",
        "\r\n",
        "      for count, (i,j) in enumerate(index_pairs):\r\n",
        "        x_pairs[count] = np.concatenate((x_train[i],x_train[j])) # Concatenate the feature vectors for each pair.\r\n",
        "        y_pairs[count] = y_train[i] == y_train[j] # Check if the pair comes from the same class or not.\r\n",
        "    \r\n",
        "    # If x_test is supplied, we want to construct all pairs combining the test data and the training data.\r\n",
        "    elif x_test is not None and y_test is not None:\r\n",
        "      index_pairs = itertools.product(range(len(x_train)), range(len(x_test))) # Get all two-way permutations of the indexes.\r\n",
        "\r\n",
        "      n_pairs = len(x_train)*len(x_test) # Get the number of pairs.\r\n",
        "      x_pairs = np.zeros((n_pairs, x_train.shape[1]*2)) # Create a blank array to hold the concatenated feature vector pairs.\r\n",
        "      y_pairs = np.zeros(n_pairs) # Create a blank vector to hold class similarity flag.\r\n",
        "\r\n",
        "      for count, (i,j) in enumerate(index_pairs):\r\n",
        "        x_pairs[count] = np.concatenate((x_train[i],x_test[j])) # Concatenate the feature vectors for each pair.\r\n",
        "        y_pairs[count] = y_train[i] == y_test[j] # Check if the pair comes from the same class or not.\r\n",
        "\r\n",
        "    else: \r\n",
        "      raise Exception(\"If x_test is provided, then y_test must be provided too.\")\r\n",
        "\r\n",
        "    # Return the concatenated feature vectors for each pair, and the binary label whether they are from the same class.\r\n",
        "    return x_pairs, y_pairs\r\n",
        "\r\n",
        "\r\n",
        "  def fit(self, x_train = None, y_train = None):\r\n",
        "    \"\"\"\r\n",
        "    Method to fit the SVM on the pairwise training data.\r\n",
        "    \"\"\"\r\n",
        "    if (x_train is None) ^ (y_train is None):\r\n",
        "      raise Exception(\"Either both the x_train and y_train datasets should be supplied, or neither.\")\r\n",
        "\r\n",
        "    # Get all pairwise combinations of the training data.\r\n",
        "    elif x_train is None and y_train is None:\r\n",
        "      x_pairs, y_pairs = self.construct_pairs()\r\n",
        "\r\n",
        "    else:\r\n",
        "      x_pairs, y_pairs = self.construct_pairs(x_train, y_train)\r\n",
        "\r\n",
        "    print(x_pairs, y_pairs)\r\n",
        "\r\n",
        "\r\n",
        "  def predict(self, x_test):\r\n",
        "    \"\"\"\r\n",
        "    Predict class labels given a set of feature data.\r\n",
        "    \"\"\"\r\n",
        "    pass\r\n",
        "  \r\n",
        "  def add_class(self, new_train, new_class):\r\n",
        "    \"\"\"\r\n",
        "    Add new participant for prediction purposes.\r\n",
        "    \"\"\"\r\n",
        "    pass"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRosD_BcAIB4",
        "outputId": "c2fffa91-94a1-43ea-d9cf-7df9031a13f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test = pairwiseSVM(C=1.0, kernel='rbf', degree=3, random_state=None) # Create a test instance of the class.\r\n",
        "\r\n",
        "# Some small test data\r\n",
        "a = np.array([[1,2,3],[4,5,6],[7,8,9]])\r\n",
        "b = np.array([[901,801,701],[602,603,604]])\r\n",
        "y1 = np.array([1,2,3])\r\n",
        "y2 = np.array([1,1])\r\n",
        "\r\n",
        "# test.construct_pairs(a,y1,b,y2)\r\n",
        "test.fit(a,y1)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 2. 3. 4. 5. 6.]\n",
            " [1. 2. 3. 7. 8. 9.]\n",
            " [4. 5. 6. 1. 2. 3.]\n",
            " [4. 5. 6. 7. 8. 9.]\n",
            " [7. 8. 9. 1. 2. 3.]\n",
            " [7. 8. 9. 4. 5. 6.]] [0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dw7uCGxjFH7-"
      },
      "source": [
        "# Run this cell to save the changes\r\n",
        "\r\n",
        "# drive.flush_and_unmount()\r\n",
        "# print('All changes made in this colab session should now be visible in Drive.')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}