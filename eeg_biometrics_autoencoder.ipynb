{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Autoencoder",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BRomans/IdMind/blob/main/eeg_biometrics_autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aTCrOSwlbGd"
      },
      "source": [
        "## Load libraries & initialise environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sQFvwJpfLSt"
      },
      "source": [
        "# import libraries\r\n",
        "import os\r\n",
        "import csv\r\n",
        "import random\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import tensorflow as tf\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "sns.set(color_codes=True)\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "from google.colab import drive\r\n",
        "from sklearn.preprocessing import MinMaxScaler, RobustScaler, QuantileTransformer\r\n",
        "from copy import deepcopy\r\n",
        "from sklearn.externals import joblib\r\n",
        "from numpy.random import seed\r\n",
        "from keras.layers import Input, Dropout, Dense, LSTM, TimeDistributed, Reshape, \\\r\n",
        "          RepeatVector, MaxPooling1D, Conv1D, Flatten, Conv1DTranspose, UpSampling1D, \\\r\n",
        "          AveragePooling1D\r\n",
        "from keras.models import Model, Sequential\r\n",
        "from keras.optimizers import Adam\r\n",
        "from keras import regularizers\r\n",
        "from keras import backend as K\r\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\r\n",
        "from keras.utils import to_categorical\r\n",
        "\r\n",
        "from tensorflow.python.client import device_lib\r\n",
        "# print(device_lib.list_local_devices())"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXQT6VF9fRAK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13a92dd4-1ade-4e96-f52f-e6013f36832b"
      },
      "source": [
        "drive.mount(\"/content/drive\")\r\n",
        "dirpath = \"/content/drive/MyDrive/ml2-eeg-biometrics/train-test-data/\" "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6YB2XBaXlTy"
      },
      "source": [
        "# Seed value\r\n",
        "# Apparently you may use different seed values at each stage\r\n",
        "seed_value = 10\r\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\r\n",
        "\r\n",
        "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\r\n",
        "os.environ['PYTHONHASHSEED']=str(seed_value)\r\n",
        "\r\n",
        "# 2. Set `python` built-in pseudo-random generator at a fixed value\r\n",
        "\r\n",
        "random.seed(seed_value)\r\n",
        "\r\n",
        "# 3. Set `numpy` pseudo-random generator at a fixed value\r\n",
        "np.random.seed(seed_value)\r\n",
        "\r\n",
        "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\r\n",
        "tf.compat.v1.set_random_seed(seed_value)\r\n",
        "\r\n",
        "# 5. Configure a new global `tensorflow` session\r\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\r\n",
        "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\r\n",
        "tf.compat.v1.keras.backend.set_session(sess)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeTPxR0aYNxV"
      },
      "source": [
        "## Load & Process Data\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BInAGYqORGnb"
      },
      "source": [
        "##### Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlN5H_lIhPin"
      },
      "source": [
        "To begin with, we load the 3 parts of the dataset, training, test and validation that we split in the pre-processing phase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAqlAto997Wp"
      },
      "source": [
        "def load_datasets():\r\n",
        "  x_train = np.asarray(np.load(dirpath + 'x_train.npy')).astype(np.float32)\r\n",
        "  x_test = np.asarray(np.load(dirpath + 'x_test.npy', allow_pickle=True)).astype(np.float32)\r\n",
        "  x_valid = np.asarray(np.load(dirpath + 'x_valid.npy', allow_pickle=True)).astype(np.float32)\r\n",
        "  return x_train, x_test, x_valid"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tn-ErKYzhZZx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "950457f3-964d-4b1a-e0d3-9b441e25c78b"
      },
      "source": [
        "x_train_unscaled, x_test_unscaled, x_valid_unscaled  = load_datasets()\r\n",
        "print(\"Data loaded. Shapes:\")\r\n",
        "print(x_train_unscaled.shape, x_test_unscaled.shape, x_valid_unscaled.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data loaded. Shapes:\n",
            "(6665, 2500, 9) (419, 2500, 9) (1300, 2500, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EporEztRJ5L"
      },
      "source": [
        "##### Plot distributions of unscaled data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "je6ycNzG3EMw"
      },
      "source": [
        "cols = ['Statistic','F3', 'F4', 'FC3', 'FC4', 'C3', 'Cz', 'C4', 'CP3', 'CP4']\r\n",
        "def data_summary(dataset, label):\r\n",
        "  \"\"\" \r\n",
        "  input:\r\n",
        "    dataset     the three dimensional input (n_samples, n_timepoints, n_features) \r\n",
        "\r\n",
        "    Prints histograms for the 9 features individually\r\n",
        "  returns: \r\n",
        "    summ_df     pd.DataFrame containing summary statistics for the 9 features.\r\n",
        "  \"\"\"\r\n",
        "  data = dataset.reshape((dataset.shape[0] * dataset.shape[1], dataset.shape[2])) # Reshape to 2D (n_samples*n_timepoints, n_features)\r\n",
        "  \r\n",
        "  # Calculate the summary statistics.\r\n",
        "  min   = data.min(axis=0).reshape(1, data.shape[1])                  # Calculate the minimum over the rows for each column.\r\n",
        "  max   = data.max(axis=0).reshape(1, data.shape[1])                  # Then reshape the result to one row and n_cols=n_features, to make it easier to combine later.\r\n",
        "  mean  = data.mean(axis=0).reshape(1, data.shape[1])\r\n",
        "  var   = data.var(axis=0).reshape(1, data.shape[1])\r\n",
        "  q01   = np.quantile(data, 0.01, axis=0).reshape(1, data.shape[1])\r\n",
        "  q99   = np.quantile(data, 0.99, axis=0).reshape(1, data.shape[1])\r\n",
        "\r\n",
        "  names=np.array([['min','max','mean','var','1st percentile', '99th percentile']]).reshape(6,1) # Create a column of names for the summary stats.\r\n",
        "  stats = np.concatenate((min,max,mean,var,q01,q99), axis=0)          # Combine the summary stats in one array\r\n",
        "\r\n",
        "  summ = np.concatenate((names, np.round(stats, 4)), axis=1)          # Combine the summary stats with their names.\r\n",
        "  summ_df = pd.DataFrame(summ, columns=cols)                          # Create a dataframe and supply the channel names as columns.\r\n",
        "\r\n",
        "  # Plot histograms per channel.\r\n",
        "  fig, axes = plt.subplots(3,3, figsize = (9,9))\r\n",
        "  axes=axes.ravel()\r\n",
        "  for i in range(9): # Loop through the channels.\r\n",
        "    axes[i].hist(data[:,i], range= (q01[0,i], q99[0,i]),   density=True)    # Add histogram subplot for the values of that channel.\r\n",
        "    axes[i].title.set_text(cols[i+1])                                       # Add a title with the channel name.\r\n",
        "  fig.suptitle(\"Distribution for each channel (between 1st & 99th percentile) of \" + label + \" dataset\" , size=16)\r\n",
        "  fig.tight_layout(rect=[0, 0.03, 1, 0.95])                                 # Cut the plot space to make space for the global title.\r\n",
        "\r\n",
        "  return summ_df"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPhAKBtY04dN"
      },
      "source": [
        "# Plot distributions of each channel.\r\n",
        "unscaled_training_summary = data_summary(x_train_unscaled, \"Training\")\r\n",
        "unscaled_test_summary = data_summary(x_test_unscaled, \"Test\")\r\n",
        "unscaled_valid_summary = data_summary(x_valid_unscaled, \"Validation\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obsst4fTzSK4"
      },
      "source": [
        "### Band-pass filter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6M8UO7FRueQ"
      },
      "source": [
        "##### Create the filters and apply across the whole data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDMKQR0SzQ47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "628d06f9-c271-4bae-f605-164f429b199c"
      },
      "source": [
        "from scipy import signal\r\n",
        "from copy import deepcopy\r\n",
        "\r\n",
        "low_cut = 0.1\r\n",
        "high_cut = 50.0\r\n",
        "\r\n",
        "bp = signal.butter(10, (low_cut,high_cut), 'bp', fs=500, output='sos') # Create the filter. fs is the sampling rate.\r\n",
        "\r\n",
        "# Create copies of the data\r\n",
        "x_train_filtered = deepcopy(x_train_unscaled)         # After running once in the session, I comment these out because otherwise if you re-run the cell it eats RAM.\r\n",
        "x_test_filtered = deepcopy(x_test_unscaled)\r\n",
        "x_valid_filtered = deepcopy(x_valid_unscaled)\r\n",
        "\r\n",
        "print(x_train_filtered.shape)\r\n",
        "\r\n",
        "x_train_filtered = signal.sosfilt(bp, x_train_filtered, axis=1)\r\n",
        "x_valid_filtered = signal.sosfilt(bp, x_valid_filtered, axis=1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6665, 2500, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Jttdl9hv6zj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16e72813-92b8-42aa-9e8e-f7b46d136b6b"
      },
      "source": [
        "# How many values lay beyond a threshold?\r\n",
        "threshold = 85\r\n",
        "\r\n",
        "outliers_pre_BP = abs(x_train_unscaled) > threshold\r\n",
        "outliers_post_BP = abs(x_train_filtered) > threshold\r\n",
        "                                \r\n",
        "print(\"Before BP filtering, {0:.2f}% of all values lay outside ±{1}\".format((100*np.sum(outliers_pre_BP))/(6665*2500*9), threshold))\r\n",
        "print(\"After BP filtering, {0:.2f}% of all values lay outside ±{1}\".format((100*np.sum(outliers_post_BP))/(6665*2500*9), threshold))\r\n",
        "\r\n",
        " # Number of samples with at least value outside threshold.\r\n",
        "print(\"After BP filtering, there are {0} samples with at least one value outside ±{1}\".format(np.sum(np.max(outliers_post_BP, axis=(1,2))), threshold))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before BP filtering, 1.56% of all values lay outside ±85\n",
            "After BP filtering, 0.60% of all values lay outside ±85\n",
            "After BP filtering, there are 1347 samples with at least one value outside ±85\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EQIwyM7tCAp"
      },
      "source": [
        "#### Apply scaling with quantile transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AShIoKEB5_lh"
      },
      "source": [
        "transformer = QuantileTransformer(output_distribution='normal')\r\n",
        "\r\n",
        "# Create copies so the original data remains unaltered.\r\n",
        "x_train = deepcopy(x_train_filtered)\r\n",
        "x_valid = deepcopy(x_valid_filtered)\r\n",
        "x_test = deepcopy(x_test_filtered)\r\n",
        "\r\n",
        "# Get the dimensionality for re-shaping.\r\n",
        "n_samples, n_timepoints, n_features = x_train.shape\r\n",
        "n_samples_valid = x_valid.shape[0]\r\n",
        "n_samples_test = x_test.shape[0]\r\n",
        "\r\n",
        "# Re-shape to 2D for the scaler.\r\n",
        "x_train = x_train.reshape((n_samples*n_timepoints, n_features))        \r\n",
        "x_valid = x_valid.reshape((n_samples_valid*n_timepoints, n_features))\r\n",
        "x_test = x_test.reshape((n_samples_test*n_timepoints, n_features))\r\n",
        "\r\n",
        "# Fit and apply the scaler/transformer to the datasets.\r\n",
        "x_train = transformer.fit_transform(x_train)         \r\n",
        "x_valid = transformer.transform(x_valid)            \r\n",
        "x_test = transformer.transform(x_test)    \r\n",
        "\r\n",
        "# Re-shape to 3D for input to the convolutional autoencoder.\r\n",
        "x_train = x_train.reshape((n_samples, n_timepoints, n_features)) \r\n",
        "x_valid = x_valid.reshape((n_samples_valid, n_timepoints, n_features)) \r\n",
        "x_test = x_test.reshape((n_samples_test, n_timepoints, n_features))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZQI-k4G6WYu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 846
        },
        "outputId": "d39c3f28-6f8c-4770-c531-f8b910180837"
      },
      "source": [
        " data_summary(x_train, \"Training Filtered\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Statistic</th>\n",
              "      <th>F3</th>\n",
              "      <th>F4</th>\n",
              "      <th>FC3</th>\n",
              "      <th>FC4</th>\n",
              "      <th>C3</th>\n",
              "      <th>Cz</th>\n",
              "      <th>C4</th>\n",
              "      <th>CP3</th>\n",
              "      <th>CP4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>min</td>\n",
              "      <td>-5.1993</td>\n",
              "      <td>-5.1993</td>\n",
              "      <td>-5.1993</td>\n",
              "      <td>-5.1993</td>\n",
              "      <td>-5.1993</td>\n",
              "      <td>-5.1993</td>\n",
              "      <td>-5.1993</td>\n",
              "      <td>-5.1993</td>\n",
              "      <td>-5.1993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>max</td>\n",
              "      <td>5.1993</td>\n",
              "      <td>5.1993</td>\n",
              "      <td>5.1993</td>\n",
              "      <td>5.1993</td>\n",
              "      <td>5.1993</td>\n",
              "      <td>5.1993</td>\n",
              "      <td>5.1993</td>\n",
              "      <td>5.1993</td>\n",
              "      <td>5.1993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mean</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>-0.0023</td>\n",
              "      <td>0.0055</td>\n",
              "      <td>0.0017</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>-0.0027</td>\n",
              "      <td>-0.0071</td>\n",
              "      <td>-0.0035</td>\n",
              "      <td>-0.0023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>var</td>\n",
              "      <td>0.9999</td>\n",
              "      <td>0.9961</td>\n",
              "      <td>0.9921</td>\n",
              "      <td>1.0008</td>\n",
              "      <td>0.9965</td>\n",
              "      <td>0.9927</td>\n",
              "      <td>1.0033</td>\n",
              "      <td>1.0015</td>\n",
              "      <td>0.9913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1st percentile</td>\n",
              "      <td>-2.3193</td>\n",
              "      <td>-2.332</td>\n",
              "      <td>-2.3235</td>\n",
              "      <td>-2.3425</td>\n",
              "      <td>-2.3276</td>\n",
              "      <td>-2.3356</td>\n",
              "      <td>-2.3472</td>\n",
              "      <td>-2.314</td>\n",
              "      <td>-2.3432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>99th percentile</td>\n",
              "      <td>2.3211</td>\n",
              "      <td>2.3242</td>\n",
              "      <td>2.3139</td>\n",
              "      <td>2.3255</td>\n",
              "      <td>2.3328</td>\n",
              "      <td>2.3101</td>\n",
              "      <td>2.3472</td>\n",
              "      <td>2.3283</td>\n",
              "      <td>2.3218</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Statistic       F3       F4  ...       C4      CP3      CP4\n",
              "0              min  -5.1993  -5.1993  ...  -5.1993  -5.1993  -5.1993\n",
              "1              max   5.1993   5.1993  ...   5.1993   5.1993   5.1993\n",
              "2             mean   0.0002  -0.0023  ...  -0.0071  -0.0035  -0.0023\n",
              "3              var   0.9999   0.9961  ...   1.0033   1.0015   0.9913\n",
              "4   1st percentile  -2.3193   -2.332  ...  -2.3472   -2.314  -2.3432\n",
              "5  99th percentile   2.3211   2.3242  ...   2.3472   2.3283   2.3218\n",
              "\n",
              "[6 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQ7XEKeEo8a5"
      },
      "source": [
        "##### Visualise the Raw & Scaled Signals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DEghaTsYrFO"
      },
      "source": [
        "labels=[(('F3',0), ('F4',1)), (('FC3',2), ('FC4',3)), (('C3',4), ('Cz',5), ('C4',6)), (('CP3',7), ('CP4',8))]\r\n",
        "colours= ['darkslateblue', 'orange','lightskyblue','brown','darkgreen','darkgrey','bisque','violet','palegreen']\r\n",
        "\r\n",
        "def plot_signals(sample, title=None):\r\n",
        "  fig, axes = plt.subplots(2,2, figsize = (6,6))\r\n",
        "  axes=axes.ravel()\r\n",
        "  plt.suptitle(\"Signals\" if title is None else title, size=16)\r\n",
        "  count=0\r\n",
        "  for label_group in labels:\r\n",
        "    for label, ind in label_group:\r\n",
        "      axes[count].plot(sample[:,ind], label=label,color=colours[ind], alpha=0.8)\r\n",
        "      axes[count].legend()\r\n",
        "    count+=1\r\n",
        "\r\n",
        "# plot_signals(x_train[101], title=\"Scaled Signals - x_train[0]\")\r\n",
        "plot_signals(x_train_unscaled[101], title=\"Unscaled Signals - x_train[0]\")\r\n",
        "plot_signals(x_train_filtered[101], title=\"Filtered Signals - x_train[0]\")\r\n",
        "plot_signals(x_train[101], title=\"Scaled Signals - x_train[0]\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gG4uVFIx9ZOg"
      },
      "source": [
        "## Utility\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1nJcvib9k7-"
      },
      "source": [
        "#### Experiment Tracker\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-qEtoed9hxZ"
      },
      "source": [
        "class ExperimentTracker():\r\n",
        "\r\n",
        "  def __init__(self):\r\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7PWDBiuWVX8"
      },
      "source": [
        "## Autoencoders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIUsOKCEyxv1"
      },
      "source": [
        "#### Convolutional Autoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltaV2CiYXS5J"
      },
      "source": [
        "##### Define a convolutional autoencoder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1xX-IPc1GXH"
      },
      "source": [
        "This object-orientd implementation of the Convolutional Autoencoder allows to build an extra candidate architecture to be compared with the current architecture. In additions it includes several methods (that wrap native methdos from the class Model) to plot, evaluate and save a model easily while performing an experiment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjpduhZRc2TF"
      },
      "source": [
        "path_models = \"/content/drive/MyDrive/ml2-eeg-biometrics/saved_models/\"\r\n",
        "path_encoders = \"/content/drive/MyDrive/ml2-eeg-biometrics/saved_encoders/\"\r\n",
        "\r\n",
        "class ConvAutoencoder():\r\n",
        "\r\n",
        "  def __init__(self, loss, optimizer, shape, parameters, candidate=False):\r\n",
        "      self.input_shape = shape   \r\n",
        "      self.encoder = None\r\n",
        "      self.history = None\r\n",
        "      print(\"Candidate build:\", candidate)    \r\n",
        "      self.autoencoder_model = self.build_candidate_model() if candidate else self.build_model(parameters['kernel_size'], parameters['filters'], parameters['pool_size'])\r\n",
        "      self.autoencoder_model.compile(loss=loss, optimizer=optimizer)\r\n",
        "      self.autoencoder_model.summary()\r\n",
        "  \r\n",
        "\r\n",
        "  ''' Builds the architecture of the model'''   \r\n",
        "  def build_model(self, kernel_sizes, filters, pool_sizes):\r\n",
        "      input_layer = Input(shape=self.input_shape)\r\n",
        "\r\n",
        "      # encoder\r\n",
        "      e1 = Conv1D(filters=filters[0], kernel_size=kernel_sizes[0], activation='relu', padding='same')(input_layer)\r\n",
        "      e2 = MaxPooling1D(pool_size=pool_sizes[0])(e1)\r\n",
        "      e3 = Conv1D(filters=filters[1], kernel_size=kernel_sizes[1], activation = 'relu', padding='same')(e2)\r\n",
        "      e4 = MaxPooling1D(pool_size=pool_sizes[1])(e3)\r\n",
        "      e5 = Conv1D(filters=filters[2], kernel_size=kernel_sizes[2], activation = 'relu', padding='same')(e4)\r\n",
        "      e6 = MaxPooling1D(pool_size=pool_sizes[2])(e5)\r\n",
        "      encoded = Flatten()(e6)\r\n",
        "      print(\"Encoder size: \", encoded.type_spec.shape)\r\n",
        "      self.encoder = encoded # save the encoder for later extraction\r\n",
        "\r\n",
        "      # decoder\r\n",
        "      d0 = Reshape((125,2))(encoded)\r\n",
        "      d1 = UpSampling1D(size=pool_sizes[2])(d0)\r\n",
        "      d2 = Conv1DTranspose(filters=filters[1], kernel_size=kernel_sizes[2], activation='relu', padding='same')(d1)    \r\n",
        "      d3 = UpSampling1D(size=pool_sizes[1])(d2)\r\n",
        "      d4 = Conv1DTranspose(filters=filters[2], kernel_size=kernel_sizes[1], activation='relu', padding='same')(d3)\r\n",
        "      d5 = UpSampling1D(size=pool_sizes[0])(d4)\r\n",
        "      decoded = Conv1DTranspose(filters=9, kernel_size=kernel_sizes[0], activation='linear', padding='same')(d5)\r\n",
        "\r\n",
        "      model = Model(inputs=input_layer, outputs=decoded)\r\n",
        "      model.output_shape\r\n",
        "      return model\r\n",
        "\r\n",
        "\r\n",
        "  ''' Builds the architecture of a candidate model, to be used in comparison with the current model'''   \r\n",
        "  def build_candidate_model(self):\r\n",
        "      print(\"No candidate build present, implement one first\")\r\n",
        "      return None\r\n",
        "\r\n",
        "  ''' Trains the model on the full dataset and then saves the encoder part in a file'''\r\n",
        "  def train_model_then_save(self, x_train, x_val, epochs, batch_size):\r\n",
        "      self.train_model(x_train, x_val, epochs, batch_size)\r\n",
        "      self.save_encoder(path_encoders, \"encoder_\" + str(epochs) +\"epochs\" + \"_batchsize\" + str(batch_size))\r\n",
        "\r\n",
        "  ''' Trains the model on the full dataset, requires validation split'''                     \r\n",
        "  def train_model(self, x_train, x_val, epochs, batch_size=20):\r\n",
        "      early_stopping = EarlyStopping(monitor='loss',\r\n",
        "                                      min_delta=0,\r\n",
        "                                      patience=5,\r\n",
        "                                      verbose=1, \r\n",
        "                                      mode='auto')\r\n",
        "      self.history = self.autoencoder_model.fit(x_train, x_train,\r\n",
        "                                            batch_size=batch_size,\r\n",
        "                                            epochs=epochs,\r\n",
        "                                            validation_data=(x_val, x_val),\r\n",
        "                                            callbacks=[early_stopping])\r\n",
        "      return self.history\r\n",
        "\r\n",
        "\r\n",
        "  ''' Trains the model on a single channel, no validation split'''   \r\n",
        "  def train_subset(self, x_train, epochs, batch_size=20):\r\n",
        "      history = self.autoencoder_model.fit(x_train[:,:,0], x_train[:,:,0], epochs=epochs,\r\n",
        "                  batch_size=batch_size,\r\n",
        "                  # validation_split=0.05\r\n",
        "                  )\r\n",
        "      \r\n",
        "\r\n",
        "  ''' Plots the history.\r\n",
        "  input:\r\n",
        "    history: if present, plot the history given as parameter\r\n",
        "  output:\r\n",
        "    None\r\n",
        "  '''       \r\n",
        "  def plot_history(self, history=None):\r\n",
        "      history = history if history is not None else self.history\r\n",
        "      plt.plot(history.history['loss'])\r\n",
        "      plt.plot(history.history['val_loss'])\r\n",
        "      plt.title('Model loss')\r\n",
        "      plt.ylabel('Loss')\r\n",
        "      plt.xlabel('Epoch')\r\n",
        "      plt.legend(['Train', 'Test'], loc='upper left')\r\n",
        "      plt.show()\r\n",
        "      \r\n",
        "\r\n",
        "  ''' Return the predictions for the trained data.\r\n",
        "   input:\r\n",
        "    X: the training data\r\n",
        "   output:\r\n",
        "    preds: predictions for the given training data\r\n",
        "  '''       \r\n",
        "  def eval_model(self, X):\r\n",
        "      preds = self.autoencoder_model.predict(X)\r\n",
        "      return preds\r\n",
        "\r\n",
        "\r\n",
        "  ''' Save all model information, including weights, in h5 format\r\n",
        "    input:\r\n",
        "      path: full path on drive, for example /content/drive/MyDrive/ml2-eeg-biometrics/saved_models/\r\n",
        "    output:\r\n",
        "      None\r\n",
        "  '''    \r\n",
        "  def save_model(self, path, label=''):\r\n",
        "      timestamp = pd.Timestamp.now()\r\n",
        "      model_name = label + \"_\" + str(timestamp) + \".h5\"\r\n",
        "      saved_model = self.autoencoder_model.save(path + model_name)\r\n",
        "      print(\"Model saved at \" + str(timestamp) + \" in path \" + path)\r\n",
        "\r\n",
        "  \r\n",
        "  ''' Save the encoder part of the model, including weights, in h5 format\r\n",
        "    input:\r\n",
        "      path: full path on drive, for example /content/drive/MyDrive/ml2-eeg-biometrics/saved_models/\r\n",
        "    output:\r\n",
        "      None\r\n",
        "  '''    \r\n",
        "  def save_encoder(self, path, label=''):\r\n",
        "      timestamp = pd.Timestamp.now()\r\n",
        "      model_name = label + \"_\" + str(timestamp) + \".h5\"\r\n",
        "      encoder = Model(self.autoencoder_model.input, self.encoder)\r\n",
        "      saved_encoder = encoder.save(path + model_name)\r\n",
        "      print(\"Encoder saved at \" + str(timestamp) + \" in path \" + path)\r\n",
        "\r\n",
        "  ''' Retrieve the history of the model.\r\n",
        "  input:\r\n",
        "    None\r\n",
        "  output:\r\n",
        "    history: history saved in the object model\r\n",
        "  '''\r\n",
        "  def retrieve_history(self):\r\n",
        "      return self.history\r\n",
        "\r\n",
        "\r\n",
        "  ''' Retrieve the encoder part of the model.\r\n",
        "  input:\r\n",
        "    index: the index of the encoded layer\r\n",
        "  output:\r\n",
        "    encoder: a model built with the input layer as input and the encoded layer as output\r\n",
        "  '''\r\n",
        "  def retrieve_encoder(self, index):\r\n",
        "      encoder = Model(self.autoencoder_model.input, self.autoencoder_model.get_layer(index=index).output)\r\n",
        "      return encoder\r\n",
        "  \r\n",
        "\r\n",
        "  ''' Assess the model on a subset of data\r\n",
        "  input:\r\n",
        "    X: the training data\r\n",
        "  output:\r\n",
        "    None\r\n",
        "  '''\r\n",
        "  def assess_subset(self, X):\r\n",
        "    x_pred = self.eval_model(X)\r\n",
        "    for i in range(0,len(x_1),200):\r\n",
        "      plt.plot(x_1[i,:,0], label='actual')\r\n",
        "      plt.plot(x_pred[i,:,0], label = 'predicted')\r\n",
        "      plt.show()\r\n",
        "\r\n",
        "\r\n",
        "  ''' Plot prediction for the model.\r\n",
        "  input:\r\n",
        "    X: the training data\r\n",
        "  output:\r\n",
        "    None\r\n",
        "  '''\r\n",
        "  def plot_prediction(self, X):\r\n",
        "    x_pred = candidate_model.eval_model(X)\r\n",
        "    plt.figure(figsize=(14,8))\r\n",
        "    plt.plot(X[1039,:,0], label='actual', alpha=0.7)\r\n",
        "    plt.plot(x_pred[1039,:,0], label= 'predicted',alpha=0.7)\r\n",
        "    # plt.ylim(0.475, 0.495)\r\n",
        "    plt.legend()\r\n",
        "\r\n",
        "  ''' Plot the distribution of the loss across the dataset\r\n",
        "  input:\r\n",
        "    X_pred: prediction on the training data (obtainable from eval_model())\r\n",
        "    X_train: the training data\r\n",
        "  output:\r\n",
        "    None\r\n",
        "  '''\r\n",
        "  def plot_loss_distribution(self, X_pred, x_train):\r\n",
        "    x_train_reshaped = x_train.reshape(x_train.shape[0]*x_train.shape[1], x_train.shape[2])\r\n",
        "    loss_mae = np.mean(np.abs(X_pred-x_train_reshaped), axis = 1)\r\n",
        "    plt.figure(figsize=(16,9), dpi=80)\r\n",
        "    plt.title('Loss Distribution', fontsize=16)\r\n",
        "    sns.distplot(loss_mae, bins = 20, kde= True, color = 'blue');\r\n",
        "    plt.xlim([0.0,.5])\r\n",
        "    \r\n",
        "\r\n",
        "  \"\"\" Function to plot predictions vs. the actuals for one sample.\r\n",
        "  input:\r\n",
        "    actuals   3D array (n_samplesx2500x9) - Original scaled signals.\r\n",
        "    pred      the predicted values corresponding to the actuals.\r\n",
        "    ind     The row number of the sample (2500x9) that you want to compare.\r\n",
        "    rescale   If set to true then the data is first converted back to the original scale for comparison.\r\n",
        "  \r\n",
        "  returns:\r\n",
        "    nothing\r\n",
        "\r\n",
        "  prints plots.\r\n",
        "  \"\"\"\r\n",
        "  def evaluate_prediction(self, actuals, pred, ind, rescale=False):\r\n",
        "    cols = ['F3', 'F4', 'FC3', 'FC4', 'C3', 'Cz', 'C4', 'CP3', 'CP4']\r\n",
        "\r\n",
        "    if rescale:\r\n",
        "      sample_actual = scaler.inverse_transform(actuals[ind]) # Rescale to the original scale.\r\n",
        "      sample_pred = scaler.inverse_transform(pred[ind]) \r\n",
        "    else:\r\n",
        "      sample_actual = actuals[ind]    # Get the relevant sample.\r\n",
        "      sample_pred = pred[ind]\r\n",
        "\r\n",
        "    mae_by_channel = np.mean(np.abs(sample_pred - sample_actual), axis=0) # Get the Mean Absolute Error for each channel for this sample\r\n",
        "    sample_mae = np.mean(mae_by_channel) # Get the total MAE for the sample by taking the average across the 9 channels\r\n",
        "    print(\"Sample\", ind, \"\\n   Total Mean Absolute Error:\", round(sample_mae, 8))\r\n",
        "    print(\"Mean Absolute Error by Channel:\")\r\n",
        "    for col, error in zip(cols, mae_by_channel):\r\n",
        "      print(col, \": \", round(error,8)) \r\n",
        "\r\n",
        "    fig, axes = plt.subplots(3,3, figsize=(9,9))\r\n",
        "    axes=axes.ravel()\r\n",
        "\r\n",
        "    for i in range(9):\r\n",
        "      axes[i].plot(sample_actual[:,i], label= \"Actual\")\r\n",
        "      axes[i].plot(sample_pred[:,i], label=\"Predicted\")\r\n",
        "      axes[i].title.set_text(cols[i] + str(round(mae_by_channel[i], 3)))\r\n",
        "    \r\n",
        "    plt.legend()\r\n",
        "    fig.suptitle(\"Predictions vs. Actuals - Sample \" + str(ind),size=16)\r\n",
        "    fig.tight_layout(rect=[0, 0.03, 1, 0.95])\r\n",
        "\r\n",
        "  ''' Plot loss distribution of the test set for each channel.\r\n",
        "  input:\r\n",
        "    X_test: the test data \r\n",
        "  output:\r\n",
        "    None\r\n",
        "  '''\r\n",
        "  def plot_loss_test(self, x_test):\r\n",
        "    X_pred = self.eval_model(x_test)\r\n",
        "    X_pred = X_pred.reshape(X_pred.shape[0]*X_pred.shape[1], X_pred.shape[2])\r\n",
        "\r\n",
        "    x_test_reshaped = x_test.reshape(x_test.shape[0]*x_test.shape[1], x_test.shape[2])\r\n",
        "    fig, axes = plt.subplots(9,1, figsize=(18,9))\r\n",
        "    # Plot the loss distribution for each channel individually\r\n",
        "    for i in range(x_test_reshaped.shape[1]):\r\n",
        "      loss_mae = np.abs(X_pred[:,i]-x_test_reshaped[:,i])\r\n",
        "      sns.distplot(loss_mae, bins = 100, kde= True, color = 'blue', ax=axes[i]);\r\n",
        "      axes[i].axis(xmin=0.0,xmax=0.2)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUwCCZ0ZXxdR"
      },
      "source": [
        "##### Fit the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbFLfZEL_Gdh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f2c444b-fd35-4b37-aea1-6b421fc436c8"
      },
      "source": [
        "# create the autoencoder model with the current architecture\r\n",
        "optimizer = Adam(lr=0.001)\r\n",
        "shape = (x_train.shape[1], x_train.shape[2])\r\n",
        "parameters = {\r\n",
        "          \"kernel_size\": [9, 5, 3], \r\n",
        "          \"filters\": [18, 6, 2],\r\n",
        "          \"pool_size\": [2, 5, 2]\r\n",
        "      }\r\n",
        "      \r\n",
        "model = ConvAutoencoder(loss='mae', optimizer=optimizer, shape=shape, parameters=parameters)\r\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Candidate build: False\n",
            "Encoder size:  (None, 250)\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 2500, 9)]         0         \n",
            "_________________________________________________________________\n",
            "conv1d_21 (Conv1D)           (None, 2500, 18)          1476      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_21 (MaxPooling (None, 1250, 18)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_22 (Conv1D)           (None, 1250, 6)           546       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_22 (MaxPooling (None, 250, 6)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_23 (Conv1D)           (None, 250, 2)            38        \n",
            "_________________________________________________________________\n",
            "max_pooling1d_23 (MaxPooling (None, 125, 2)            0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "reshape_5 (Reshape)          (None, 125, 2)            0         \n",
            "_________________________________________________________________\n",
            "up_sampling1d_9 (UpSampling1 (None, 250, 2)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_9 (Conv1DTr (None, 250, 6)            42        \n",
            "_________________________________________________________________\n",
            "up_sampling1d_10 (UpSampling (None, 1250, 6)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_10 (Conv1DT (None, 1250, 2)           62        \n",
            "_________________________________________________________________\n",
            "up_sampling1d_11 (UpSampling (None, 2500, 2)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_11 (Conv1DT (None, 2500, 9)           171       \n",
            "=================================================================\n",
            "Total params: 2,335\n",
            "Trainable params: 2,335\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzzXJTvNyAn0"
      },
      "source": [
        "# create the autoencoder model with the candidate architecture\r\n",
        "optimizer = Adam(lr=0.001)\r\n",
        "shape = (x_train.shape[1], x_train.shape[2])\r\n",
        "candidate_model = ConvAutoencoder(loss='mae', optimizer=optimizer, shape=shape, candidate=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDgOztHOHazh"
      },
      "source": [
        "# Train both current and candidate models\r\n",
        "\r\n",
        "# fit the model to the data\r\n",
        "nb_epochs = 1\r\n",
        "batch_size = 20\r\n",
        "x_1 = x_train[:,:,:]\r\n",
        "## Train the models on the full dataset\r\n",
        "print('Training Current model for ' + str(nb_epochs) + \" epochs and batch size of \" + str(batch_size))\r\n",
        "model.train_model_then_save(x_1, x_valid, nb_epochs, batch_size)\r\n",
        "print('============================================================')\r\n",
        "print('Training Candidate model for ' + str(nb_epochs) + \" epochs and batch size of \" + str(batch_size))\r\n",
        "#candidate_model.train_model(x_1, x_valid, nb_epochs, batch_size)\r\n",
        "print('============================================================')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64K4Tw5CcXZs"
      },
      "source": [
        "# Obtain the encoder part of the models.\r\n",
        "encoder = candidate_model.retrieve_encoder(index=7)\r\n",
        "# encoder.summary()\r\n",
        "\r\n",
        "train_pred = encoder.predict(x_train)\r\n",
        "valid_pred = encoder.predict(x_valid)\r\n",
        "\r\n",
        "timestamp = pd.Timestamp.now()\r\n",
        "np.save(dirpath + \"train_encoding_\" + candidate_model.autoencoder_model.name + \"_\" + str(timestamp) + \".npy\", train_pred)\r\n",
        "np.save(dirpath + \"valid_encoding_\" + candidate_model.autoencoder_model.name + \"_\" + str(timestamp) + \".npy\", valid_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKottLNgXpw6"
      },
      "source": [
        "model.plot_history()\r\n",
        "candidate_model.plot_history()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSGDjFwgX8pZ"
      },
      "source": [
        "##### Plot the reconstruction for individual samples.\r\n",
        "Temporary code for assessing the models on the subset of data (one channel and only 20% of timepoints)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Hm2DWhiSmeV"
      },
      "source": [
        "# model.assess_subset(x_1)\r\n",
        "candidate_model.assess_subset(x_1)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yefRYH1sc5LY"
      },
      "source": [
        "Plot prediction for the whole dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abbHkzSliPCa"
      },
      "source": [
        "model.plot_prediction(x_1)\r\n",
        "candidate_model.plot_prediction(x_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCfIG-Na0Rim"
      },
      "source": [
        "\r\n",
        "## Evaluate Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0AvXQtdVLPT"
      },
      "source": [
        "# Get the predicted values for the training set.\r\n",
        "X_pred_3D = model.eval_model(x_train)\r\n",
        "# X_pred_3D = candidate_model.eval_model(x_train_f)\r\n",
        "X_pred = X_pred_3D.reshape(X_pred_3D.shape[0]*X_pred_3D.shape[1], X_pred_3D.shape[2])\r\n",
        "# X_pred = pd.DataFrame(X_pred, columns=train.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIl53WipVnBA"
      },
      "source": [
        "##### Plot distribution of the loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OERj4N100Maz"
      },
      "source": [
        "# Plot the distribution of the loss\r\n",
        "model.plot_loss_distribution(X_pred, x_train)\r\n",
        "# candidate_model.plot_loss_distribution(X_pred, x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uQFT7_1Vtt1"
      },
      "source": [
        "##### Evaluate total re-construction for one sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKYRpNQjWF-u"
      },
      "source": [
        "model.evaluate_prediction(x_train, X_pred_3D, ind=1, rescale=False)\r\n",
        "# candidate_model.evaluate_prediction(x_train, X_pred_3D, ind=1, rescale=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ehGjGxUV4Vf"
      },
      "source": [
        "##### Plot the loss distribution of the test set (code from tutorial, needs to be edited)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sk2FB1JADjIE"
      },
      "source": [
        "# plot the loss distribution of the test set\r\n",
        "model.plot_loss_test(x_test)\r\n",
        "# candidate_model.plot_loss_test(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVIfqljx0lwt"
      },
      "source": [
        "model.save_model(path_models, \"model_20epochs\") # Get current timestamp and model number.\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}