{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Autoencoder",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BRomans/IdMind/blob/main/autoencoder_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYgNfSuNfJCu",
        "collapsed": true,
        "outputId": "00a8e752-6a0d-417c-a280-ef08b02e6fa1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install pytorch_lightning"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch_lightning\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e4/11/d5076df8e768662748bc8fe86bc9206e4e900c1784372fcd989c74cde1b3/pytorch_lightning-1.1.3-py3-none-any.whl (680kB)\n",
            "\u001b[K     |████████████████████████████████| 686kB 7.0MB/s \n",
            "\u001b[?25hCollecting fsspec[http]>=0.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/80/72ac0982cc833945fada4b76c52f0f65435ba4d53bc9317d1c70b5f7e7d5/fsspec-0.8.5-py3-none-any.whl (98kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 7.2MB/s \n",
            "\u001b[?25hCollecting PyYAML>=5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 15.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.3 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning) (1.7.0+cu101)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning) (2.4.0)\n",
            "Collecting future>=0.17.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 16.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning) (1.19.4)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning) (4.41.1)\n",
            "Collecting aiohttp; extra == \"http\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/e6/d4b6235d776c9b33f853e603efede5aac5a34f71ca9d3877adb30492eb4e/aiohttp-3.7.3-cp36-cp36m-manylinux2014_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 33.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests; extra == \"http\" in /usr/local/lib/python3.6/dist-packages (from fsspec[http]>=0.8.1->pytorch_lightning) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.3->pytorch_lightning) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.3->pytorch_lightning) (0.8)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.10.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.17.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.4.2)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.12.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.36.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.3.3)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.32.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.7.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (51.1.1)\n",
            "Requirement already satisfied: chardet<4.0,>=2.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch_lightning) (3.0.4)\n",
            "Collecting idna-ssl>=1.0; python_version < \"3.7\"\n",
            "  Downloading https://files.pythonhosted.org/packages/46/03/07c4894aae38b0de52b52586b24bf189bb83e4ddabfe2e2c8f2419eec6f4/idna-ssl-1.1.0.tar.gz\n",
            "Collecting yarl<2.0,>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/08/52b26b44bce7b818b410aee37c5e424c9ea420c557bca97dc2adac29b151/yarl-1.6.3-cp36-cp36m-manylinux2014_x86_64.whl (293kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 26.5MB/s \n",
            "\u001b[?25hCollecting async-timeout<4.0,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch_lightning) (20.3.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/35/b22524d6b9cacfb4c5eff413a069bbc17c6ea628e54da5c6c989998ced5f/multidict-5.1.0-cp36-cp36m-manylinux2014_x86_64.whl (141kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 31.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests; extra == \"http\"->fsspec[http]>=0.8.1->pytorch_lightning) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests; extra == \"http\"->fsspec[http]>=0.8.1->pytorch_lightning) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests; extra == \"http\"->fsspec[http]>=0.8.1->pytorch_lightning) (2020.12.5)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (3.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (3.4.0)\n",
            "Building wheels for collected packages: PyYAML, future, idna-ssl\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=44621 sha256=6c1023ae0c4771d35a4fbe453cc233f8c4b177403ac77295db9bc4fed34b02d9\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp36-none-any.whl size=491057 sha256=f4413794e2aab40a04a2a94f6f2f20acb39eee054533ec569f3be469cbe4b354\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "  Building wheel for idna-ssl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for idna-ssl: filename=idna_ssl-1.1.0-cp36-none-any.whl size=3163 sha256=e4460bd468ea29f905848c43ff012e9ff6d8367ef4d18352108603f1010f3d3d\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/00/b3/32d613e19e08a739751dd6bf998cfed277728f8b2127ad4eb7\n",
            "Successfully built PyYAML future idna-ssl\n",
            "Installing collected packages: idna-ssl, multidict, yarl, async-timeout, aiohttp, fsspec, PyYAML, future, pytorch-lightning\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "Successfully installed PyYAML-5.3.1 aiohttp-3.7.3 async-timeout-3.0.1 fsspec-0.8.5 future-0.18.2 idna-ssl-1.1.0 multidict-5.1.0 pytorch-lightning-1.1.3 yarl-1.6.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sQFvwJpfLSt"
      },
      "source": [
        "import numpy as np\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "from google.colab import drive\r\n",
        "import os\r\n",
        "import pickle\r\n",
        "from pathlib import Path\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import pytorch_lightning as pl\r\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXQT6VF9fRAK",
        "outputId": "3b2e87cf-60d1-4499-b5bf-eb73234628c7"
      },
      "source": [
        "drive.mount(\"/content/drive\")\r\n",
        "filepath = \"/content/drive/MyDrive/ml2-eeg-biometrics/eeg_dataset_right_hand_task_subset_9channels.csv\"\r\n",
        "# os.chdir('/content/drive/MyDrive/ml2-eeg-biometrics/prep-data')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoKUCENPWgfV",
        "outputId": "7e2d088f-6820-4622-a239-2388cc722c43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# df=pd.read_csv(filepath)\r\n",
        "print(df.shape)\r\n",
        "df.dropna(axis=1,how='all',inplace=True)\r\n",
        "print(df.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20960781, 15)\n",
            "(20960781, 14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNPxGcQ7d1Xw",
        "outputId": "cb56a007-54af-4832-d344-2a7dfa1d21ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(df.dtypes)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Participant     object\n",
            "Date             int64\n",
            "Run             object\n",
            "Task             int64\n",
            "Trial            int64\n",
            "F3             float64\n",
            "F4             float64\n",
            "FC3            float64\n",
            "FC4            float64\n",
            "C3             float64\n",
            "Cz             float64\n",
            "C4             float64\n",
            "CP3            float64\n",
            "CP4            float64\n",
            "dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FlBa6ByYwbR",
        "outputId": "34623a0c-45e7-42c2-a9d7-3cf577659950",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Create a train-validation-test split.\r\n",
        "# For testing we want to take a separate person entirely (let's take S12) - this constitutes 5% of the total dataset.\r\n",
        "# For validation we want to keep it equal across participants and sessions. We'll take 1 run per session for each of the participants. \r\n",
        "# # This is one sixth of the remaining data which equates to 15.8% of the total dataset. Thus, we keep 79.2% for training data.\r\n",
        "\r\n",
        "drop_cols = ['Participant','Date', 'Run', 'Task', 'Trial']\r\n",
        "# Convert Partipant ID to an integer column 'Target' so that pytorch can handle it.\r\n",
        "\r\n",
        "df['Target'] = df['Participant'].astype('category').cat.codes.values\r\n",
        "\r\n",
        "test_df = df[df['Participant']=='S12'].drop(drop_cols, axis=1)\r\n",
        "print(\"test_df shape:\", test_df.shape)\r\n",
        "\r\n",
        "# Run5 looks most complete in the data.\r\n",
        "valid_df = df[df['Run']=='Run5'].drop(drop_cols, axis=1)\r\n",
        "print(\"valid_df shape:\", valid_df.shape)\r\n",
        "\r\n",
        "# Take the rest for training data\r\n",
        "train_df = df[~ ((df['Run']=='Run5') & (df['Participant']=='S12'))].drop(drop_cols, axis=1)\r\n",
        "print(\"train_df shape:\", train_df.shape)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_df shape: (1047500, 10)\n",
            "valid_df shape: (3425000, 10)\n",
            "train_df shape: (20785781, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JM4ZS-LcIQp"
      },
      "source": [
        "x_test = torch.tensor(test_df.drop('Target', axis=1).values)\r\n",
        "y_test = torch.tensor(test_df['Target'].values)\r\n",
        "\r\n",
        "x_valid = torch.tensor(valid_df.drop('Target', axis=1).values)\r\n",
        "y_valid = torch.tensor(valid_df['Target'].values)\r\n",
        "\r\n",
        "x_train = torch.tensor(train_df.drop('Target', axis=1).values)\r\n",
        "y_train = torch.tensor(train_df['Target'].values)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVewsritg1O9"
      },
      "source": [
        "# df = pd.read_csv('File_explaination.csv')\r\n",
        "# print(df)\r\n",
        "# files = df.get('Filename')\r\n",
        "# print(files[8384])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBk-BdVZodpb"
      },
      "source": [
        "# class RightHandTrain(Dataset):\r\n",
        "\r\n",
        "#   def __init__(self, train_split):\r\n",
        "#     df = pd.read_csv('File_explaination.csv')\r\n",
        "#     self.files = df.get('Filename')\r\n",
        "#     self.train_split = train_split\r\n",
        "#     self.X = [None] * int(len(self.files)*self.train_split)\r\n",
        "\r\n",
        "#   def __len__(self):\r\n",
        "#     return int(len(self.files)*self.train_split)\r\n",
        "\r\n",
        "#   def __getitem__(self, idx):\r\n",
        "#     if self.X[idx] is None:\r\n",
        "#       self.X[idx] = torch.load(self.files[idx])\r\n",
        "\r\n",
        "#     return self.X[idx]\r\n",
        "\r\n",
        "# class RightHandVal(Dataset):\r\n",
        "\r\n",
        "#   def __init__(self, val_split):\r\n",
        "#     df = pd.read_csv('File_explaination.csv')\r\n",
        "#     self.files = df.get('Filename')\r\n",
        "#     self.val_split = val_split\r\n",
        "#     self.X = [None] * (int(len(self.files)*self.val_split)-1)\r\n",
        "\r\n",
        "#   def __len__(self):\r\n",
        "#     return int(len(self.files)*self.val_split) -1\r\n",
        "\r\n",
        "#   def __getitem__(self, idx):\r\n",
        "#     idx += int(len(self.files) * (1 - self.val_split)) +1 \r\n",
        "#     if self.X[idx] is None:\r\n",
        "#       self.X[idx] = torch.load(self.files[idx])\r\n",
        "\r\n",
        "#     return self.X[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-86gY8U08CHX"
      },
      "source": [
        "# ds_train = RightHandTrain(0.6)\r\n",
        "# ds = RightHandTrain(0.6)\r\n",
        "# #x_train, x_test = train_test_split(ds)\r\n",
        "# len(ds)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQFPumHChA5K"
      },
      "source": [
        "# x = torch.load('./A4|0|0|0.pt')\r\n",
        "# x = x.view(1,29,2500)\r\n",
        "# x = x.float()\r\n",
        "# print(x.size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssWE5nnKfY9q"
      },
      "source": [
        "# class Autoencoder(pl.LightningModule):\r\n",
        "\r\n",
        "#   def __init__(self):\r\n",
        "#     super().__init__()\r\n",
        "      \r\n",
        "#     # encoder layers \r\n",
        "#     self.conv1 = nn.Conv1d(29, 50, 5)  \r\n",
        "#     self.conv2 = nn.Conv1d(50, 20, 5)\r\n",
        "#     self.conv3 = nn.Conv1d(20, 5, 5)\r\n",
        "\r\n",
        "#     # decoder layers\r\n",
        "#     self.t_conv1 = nn.ConvTranspose1d(5, 20, 5)\r\n",
        "#     self.t_conv2 = nn.ConvTranspose1d(20, 50, 5)\r\n",
        "#     self.t_conv3 = nn.ConvTranspose1d(50, 29, 5)\r\n",
        "\r\n",
        "#     # pooling layer to reduce dims by two\r\n",
        "#     #self.pool = nn.MaxPool1d(2)\r\n",
        "\r\n",
        "#     # activation function\r\n",
        "#     self.act = nn.LeakyReLU(0.1)\r\n",
        "\r\n",
        "#     self.loss = nn.MSELoss()\r\n",
        "\r\n",
        "#   def forward(self, x):\r\n",
        "#     # Encode  \r\n",
        "#     x = self.act(self.conv1(x))\r\n",
        "#     x = self.act(self.conv2(x))\r\n",
        "#     x = self.act(self.conv3(x))\r\n",
        "\r\n",
        "#     # Decode\r\n",
        "#     x = self.act(self.t_conv1(x))\r\n",
        "#     x = self.act(self.t_conv2(x))\r\n",
        "#     x = self.act(self.t_conv3(x))\r\n",
        "#     return x\r\n",
        "\r\n",
        "#   def training_step(self, batch, batch_idx):\r\n",
        "#     x = batch\r\n",
        "#     x_hat = self(x)\r\n",
        "#     loss = self.loss(x_hat, x)\r\n",
        "#     return loss\r\n",
        "\r\n",
        "#   def configure_optimizers(self):\r\n",
        "#     return torch.optim.Adam(self.parameters(), lr=0.02)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4VwaRDEji_5"
      },
      "source": [
        "# ae = Autoencoder()\r\n",
        "# print(ae(x).size())\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}