{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Autoencoder",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BRomans/IdMind/blob/main/autoencoder_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYgNfSuNfJCu",
        "collapsed": true
      },
      "source": [
        "!pip install pytorch_lightning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sQFvwJpfLSt"
      },
      "source": [
        "import numpy as np\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "from google.colab import drive\r\n",
        "import os\r\n",
        "import pickle\r\n",
        "from pathlib import Path\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import pytorch_lightning as pl\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "\r\n",
        "from torchvision import datasets, transforms\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTq-S39gl7Yp"
      },
      "source": [
        "transform = transforms.ToTensor()\r\n",
        "\r\n",
        "test_data = datasets.CIFAR10(root='data', train=False, download=True, transform=transform)\r\n",
        "test_data\r\n",
        "\r\n",
        "test_loader = DataLoader(test_data, batch_size=32, num_workers=0)\r\n",
        "\r\n",
        "#Obtain one batch of training images\r\n",
        "dataiter = iter(test_loader)\r\n",
        "images, labels = dataiter.next()\r\n",
        "images = images.numpy() # convert images to numpy for display\r\n",
        "\r\n",
        "images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbeIUA2WoIvR"
      },
      "source": [
        "def imshow(img):\r\n",
        "    img = img / 2 + 0.5  \r\n",
        "    plt.imshow(np.transpose(img, (1, 2, 0))) \r\n",
        "\r\n",
        "#Plot the images\r\n",
        "fig = plt.figure(figsize=(12, 12))\r\n",
        "# display 20 images\r\n",
        "for idx in np.arange(len(images)):\r\n",
        "    ax = fig.add_subplot(11, 3, idx+1, xticks=[], yticks=[])\r\n",
        "    imshow(images[idx])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXQT6VF9fRAK"
      },
      "source": [
        "drive.mount(\"/content/drive\")\r\n",
        "filepath = \"/content/drive/MyDrive/ml2-eeg-biometrics/eeg_dataset_right_hand_task_subset_9channels.csv\"\r\n",
        "# os.chdir('/content/drive/MyDrive/ml2-eeg-biometrics/prep-data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoKUCENPWgfV"
      },
      "source": [
        "# df=pd.read_csv(filepath)\r\n",
        "print(df.shape)\r\n",
        "df.dropna(axis=1,how='all',inplace=True)\r\n",
        "print(df.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNPxGcQ7d1Xw"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FlBa6ByYwbR"
      },
      "source": [
        "# Create a train-validation-test split.\r\n",
        "# For testing we want to take a separate person entirely (let's take S12) - this constitutes 5% of the total dataset.\r\n",
        "# For validation we want to keep it equal across participants and sessions. We'll take 1 run per session for each of the participants. \r\n",
        "# # This is one sixth of the remaining data which equates to 15.8% of the total dataset. Thus, we keep 79.2% for training data.\r\n",
        "\r\n",
        "drop_cols = ['Participant','Date', 'Run', 'Task', 'Trial']\r\n",
        "# Convert Partipant ID to an integer column 'Target' so that pytorch can handle it.\r\n",
        "\r\n",
        "df['Target'] = df['Participant'].astype('category').cat.codes.values\r\n",
        "\r\n",
        "test_df = df[df['Participant']=='S12'].drop(drop_cols, axis=1)\r\n",
        "print(\"test_df shape:\", test_df.shape)\r\n",
        "\r\n",
        "# Run5 looks most complete in the data.\r\n",
        "valid_df = df[df['Run']=='Run5'].drop(drop_cols, axis=1)\r\n",
        "print(\"valid_df shape:\", valid_df.shape)\r\n",
        "\r\n",
        "# Take the rest for training data\r\n",
        "train_df = df[~ ((df['Run']=='Run5') & (df['Participant']=='S12'))].drop(drop_cols, axis=1)\r\n",
        "print(\"train_df shape:\", train_df.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JM4ZS-LcIQp"
      },
      "source": [
        "x_test = torch.tensor(test_df.drop('Target', axis=1).values)\r\n",
        "y_test = torch.tensor(test_df['Target'].values)\r\n",
        "\r\n",
        "x_valid = torch.tensor(valid_df.drop('Target', axis=1).values)\r\n",
        "y_valid = torch.tensor(valid_df['Target'].values)\r\n",
        "\r\n",
        "x_train = torch.tensor(train_df.drop('Target', axis=1).values)\r\n",
        "y_train = torch.tensor(train_df['Target'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVtsXbDKjuZl"
      },
      "source": [
        "print(x_train.shape)\r\n",
        "print(np.unique(y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVewsritg1O9"
      },
      "source": [
        "# df = pd.read_csv('File_explaination.csv')\r\n",
        "# print(df)\r\n",
        "# files = df.get('Filename')\r\n",
        "# print(files[8384])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBk-BdVZodpb"
      },
      "source": [
        "# class RightHandTrain(Dataset):\r\n",
        "\r\n",
        "#   def __init__(self, train_split):\r\n",
        "#     df = pd.read_csv('File_explaination.csv')\r\n",
        "#     self.files = df.get('Filename')\r\n",
        "#     self.train_split = train_split\r\n",
        "#     self.X = [None] * int(len(self.files)*self.train_split)\r\n",
        "\r\n",
        "#   def __len__(self):\r\n",
        "#     return int(len(self.files)*self.train_split)\r\n",
        "\r\n",
        "#   def __getitem__(self, idx):\r\n",
        "#     if self.X[idx] is None:\r\n",
        "#       self.X[idx] = torch.load(self.files[idx])\r\n",
        "\r\n",
        "#     return self.X[idx]\r\n",
        "\r\n",
        "# class RightHandVal(Dataset):\r\n",
        "\r\n",
        "#   def __init__(self, val_split):\r\n",
        "#     df = pd.read_csv('File_explaination.csv')\r\n",
        "#     self.files = df.get('Filename')\r\n",
        "#     self.val_split = val_split\r\n",
        "#     self.X = [None] * (int(len(self.files)*self.val_split)-1)\r\n",
        "\r\n",
        "#   def __len__(self):\r\n",
        "#     return int(len(self.files)*self.val_split) -1\r\n",
        "\r\n",
        "#   def __getitem__(self, idx):\r\n",
        "#     idx += int(len(self.files) * (1 - self.val_split)) +1 \r\n",
        "#     if self.X[idx] is None:\r\n",
        "#       self.X[idx] = torch.load(self.files[idx])\r\n",
        "\r\n",
        "#     return self.X[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-86gY8U08CHX"
      },
      "source": [
        "# ds_train = RightHandTrain(0.6)\r\n",
        "# ds = RightHandTrain(0.6)\r\n",
        "# #x_train, x_test = train_test_split(ds)\r\n",
        "# len(ds)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQFPumHChA5K"
      },
      "source": [
        "# x = torch.load('./A4|0|0|0.pt')\r\n",
        "# x = x.view(1,29,2500)\r\n",
        "# x = x.float()\r\n",
        "# print(x.size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssWE5nnKfY9q"
      },
      "source": [
        "# class Autoencoder(pl.LightningModule):\r\n",
        "\r\n",
        "#   def __init__(self):\r\n",
        "#     super().__init__()\r\n",
        "      \r\n",
        "#     # encoder layers \r\n",
        "#     self.conv1 = nn.Conv1d(29, 50, 5)  \r\n",
        "#     self.conv2 = nn.Conv1d(50, 20, 5)\r\n",
        "#     self.conv3 = nn.Conv1d(20, 5, 5)\r\n",
        "\r\n",
        "#     # decoder layers\r\n",
        "#     self.t_conv1 = nn.ConvTranspose1d(5, 20, 5)\r\n",
        "#     self.t_conv2 = nn.ConvTranspose1d(20, 50, 5)\r\n",
        "#     self.t_conv3 = nn.ConvTranspose1d(50, 29, 5)\r\n",
        "\r\n",
        "#     # pooling layer to reduce dims by two\r\n",
        "#     #self.pool = nn.MaxPool1d(2)\r\n",
        "\r\n",
        "#     # activation function\r\n",
        "#     self.act = nn.LeakyReLU(0.1)\r\n",
        "\r\n",
        "#     self.loss = nn.MSELoss()\r\n",
        "\r\n",
        "#   def forward(self, x):\r\n",
        "#     # Encode  \r\n",
        "#     x = self.act(self.conv1(x))\r\n",
        "#     x = self.act(self.conv2(x))\r\n",
        "#     x = self.act(self.conv3(x))\r\n",
        "\r\n",
        "#     # Decode\r\n",
        "#     x = self.act(self.t_conv1(x))\r\n",
        "#     x = self.act(self.t_conv2(x))\r\n",
        "#     x = self.act(self.t_conv3(x))\r\n",
        "#     return x\r\n",
        "\r\n",
        "#   def training_step(self, batch, batch_idx):\r\n",
        "#     x = batch\r\n",
        "#     x_hat = self(x)\r\n",
        "#     loss = self.loss(x_hat, x)\r\n",
        "#     return loss\r\n",
        "\r\n",
        "#   def configure_optimizers(self):\r\n",
        "#     return torch.optim.Adam(self.parameters(), lr=0.02)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4VwaRDEji_5"
      },
      "source": [
        "# ae = Autoencoder()\r\n",
        "# print(ae(x).size())\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}